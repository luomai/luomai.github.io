[{"authors":["admin"],"categories":null,"content":"I am a research associate in the Department of Computing at Imperial College London. In July 2020, I will start as an Assistant Professor in the School of Informatics at the University of Edinburgh. My research aims to build:\n Scalable AI systems for training graph neural networks, large vision/NLP models, and deep reinforcement learning models. Self-driving data systems that can analyse various data in real-time, sense data workloads and adapt system parameters through machine learning. Federated learning systems that can exploit edge decentralised data and emerging edge/in-network/cloud computing platforms.   I am looking for PhD and MSc by Research students. If you are interested, please contact me following a useful Guideline.   ","date":1590969600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1590969600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://luomai.netlify.app/author/luo-mai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/luo-mai/","section":"authors","summary":"I am a research associate in the Department of Computing at Imperial College London. In July 2020, I will start as an Assistant Professor in the School of Informatics at the University of Edinburgh.","tags":null,"title":"Luo Mai","type":"authors"},{"authors":null,"categories":null,"content":"Today\u0026rsquo;s machine learning systems must cope with growing complex models and increasingly complicated deployment environments, making them difficult to constantly deliver high performance with an empirical configuration. To address this, KungFu enables machine learning users to realise adaptive distributed training policies using high-level training monitoring and control APIs. KungFu has a fast and scalable runtime which can automatically scale out policy execution onto distributed GPU servers. Large-scale cluster experiments show that KungFu not only enables real-world adaptive training use cases, but also out-performs state-of-the-art distributed training systems including Horovod and Parameters Servers.\n","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"511bc777d1f6350b91dcaec24c2cc6fb","permalink":"https://luomai.netlify.app/project/kungfu/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/project/kungfu/","section":"project","summary":"An Adaptive and Fast Distributed Machine Learning Library [![GitHub stars](https://img.shields.io/github/stars/lsds/kungfu.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/lsds/kungfu/stargazers/)","tags":["Deep Learning"],"title":"KungFu","type":"project"},{"authors":["Marcel Wagenlander","Luo Mai","Guo Li","Peter Pietzuch"],"categories":null,"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"f8af5e7249f7c40944769bd5268555f1","permalink":"https://luomai.netlify.app/publication/2020-hotcloud-spotnik/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/publication/2020-hotcloud-spotnik/","section":"publication","summary":"To achieve higher utilisation, cloud providers offer VMs with GPUs as lower-cost transient cloud resources. Transient VMs can be revoked at short notice and vary in their availability. This poses challenges to distributed machine learning (ML) jobs, which perform long-running stateful computation in which many workers maintain and synchronise model replicas. With transient VMs, existing systems either require a fixed number of reserved VMs or degrade performance when recovering from revoked transient VMs. We believe that future distributed ML systems must be de- signed from the ground up for transient cloud resources. This paper describes SPOTNIK, a system for training ML models that features a more adaptive design to accommodate transient VMs: (i) SPOTNIK uses an adaptive implementation of the all-reduce collective communication operation. As workers on transient VMs are revoked, SPOTNIK updates its membership and uses the all-reduce ring to recover; and (ii) SPOTNIK supports the adaptation of the synchronisation strategy between workers. This allows a training job to switch between different strategies in response to the revocation of transient VMs. Our experiments show that, after VM revocation, SPOTNIK recovers training within 300 ms for ResNet/ImageNet.","tags":"","title":"Spotnik: Designing Distributed Machine Learning for Transient Cloud Resources","type":"publication"},{"authors":null,"categories":null,"content":"TensorLayer is a popular open-source TensorFlow-based deep learning and reinforcement library. It provides rich neural layers, pre-trained neural networks, data processing, model management and distributed training to facilitate the development of a wide spectrum of deep learning algorithms. TensorLayer has a transparent and flexible programming model, and thus suitable to customise deep neural networks for deployment and research purposes. It exhibits superior performance due to the low-cost integration with the TensorFlow backend. TensorLayer is easy to learn by providing massive tutorials, examples and real-world application codes. Since open-sourced in 2017, it has attracted more than 300,000 downloads, 6000 stars on Github, and 90 contributors around the world. TensorLayer is recently awarded the 2017 best open-source software by the prestigious ACM multimedia community.\n","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"802d61c9c8364c0f2a2655749425d54c","permalink":"https://luomai.netlify.app/project/tensorlayer/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/project/tensorlayer/","section":"project","summary":"A Simple, Flexible and Comprehensive Deep Learning Library [![GitHub stars](https://img.shields.io/github/stars/tensorlayer/tensorlayer.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/tensorlayer/tensorlayer/stargazers/)","tags":["Deep Learning"],"title":"TensorLayer","type":"project"},{"authors":null,"categories":null,"content":"Estimating human pose is a core task in many multimedia applications. To fully achieve its promise, users often need to customise pose estimation systems for best possible accuracy, and optimise the systems so that they can achieve real-time processing of high-resolution video streams. To meet these needs, we introduce HyperPose, a library for building pose estimation systems. HyperPose provides a large collection of high-level APIs to help users develop pose estimation algorithms that can achieve high accuracy in the wild. HyperPose further provides a high-performance algorithm execution engine. This engine has a high-performance dataflow for executing pose estimation algorithms. It dynamically dispatches dataflow operators onto CPUs/GPUs, which maximises hardware efficiency, thus achieving real-time processing. Evaluation result show that HyperPose allows users to declare many useful pose estimation algorithms. It also out-performs the performance of state-of-the-art pose estimation systems by up to 3.1x.\n","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"ed8e52ffeba07d28058b5554cd9c0009","permalink":"https://luomai.netlify.app/project/hyperpose/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/project/hyperpose/","section":"project","summary":"A Flexible Library for Real-time Human Pose Estimation [![GitHub stars](https://img.shields.io/github/stars/tensorlayer/hyperpose.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/tensorlayer/hyperpose/stargazers/)","tags":["Deep Learning"],"title":"HyperPose","type":"project"},{"authors":[],"categories":null,"content":"","date":1572181200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572181200,"objectID":"4e053c4645d288307aee6c84c1ac258f","permalink":"https://luomai.netlify.app/talk/2019-kungfu-sosp/","publishdate":"2019-10-27T13:00:00Z","relpermalink":"/talk/2019-kungfu-sosp/","section":"talk","summary":"Adaptive distributed training of deep learning models","tags":[],"title":"SOSP AI Systems Workshop","type":"talk"},{"authors":["Alexandros Koliousis","Pijika Watcharapichat","Matthias Weidlich","Luo Mai","Paolo Costa","Peter Pietzuch"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"0ebdd56ec8701114a5aba1877375c187","permalink":"https://luomai.netlify.app/publication/2019-vldb-crossbow/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/2019-vldb-crossbow/","section":"publication","summary":"Deep learning models are trained on servers with many GPUs, and training must scale with the number of GPUs. Systems such as TensorFlow and Caffe2 train models with parallel synchronous stochastic gradient descent: they process a batch of training data at a time, partitioned across GPUs, and average the resulting partial gradients to obtain an updated global model. To fully utilise all GPUs, systems must increase the batch size, which hinders statistical efficiency. Users tune hyper-parameters such as the learning rate to compensate for this, which is complex and model-specific. We describe Crossbow, a new single-server multi-GPU system for training deep learning models that enables users to freely choose their preferred batch size---however small---while scaling to multiple GPUs. Crossbow uses many parallel model replicas and avoids reduced statistical efficiency through a new synchronous training method. We introduce SMA, a synchronous variant of model averaging in which replicas independently explore the solution space with gradient descent, but adjust their search synchronously based on the trajectory of a globally-consistent average model. Crossbow achieves high hardware efficiency with small batch sizes by potentially training multiple model replicas per GPU, automatically tuning the number of replicas to maximise throughput. our experiments show that Crossbow improves the training time of deep learning models on an 8-GPU server by 1.3--4X compared to TensorFlow.","tags":"","title":"CrossBow: Scaling Deep Learning with Small Batch Sizes on Multi-GPU Servers","type":"publication"},{"authors":null,"categories":null,"content":"Deep Reinforcement Learning (DRL) has become the foundation of many multimedia applications. To fully achieve its promise, multi-media users are looking for a library that allows them to efficiently design and test DRL agents and integrate the agents into their ap-plications. In this project, we introduce RLzoo, a novel DRL library that makes it easy to design, test and deploy DRL agents. RLzoo has high-level expressive APIs which enable its users to efficiently develop DRL agents. RLzoo users can leverage an automatic agent construction algorithm to seamlessly adopt custom agent modules,e.g., custom neural networks, which is the key for tuning agents for achieving the best possible performance. RLzoo users can access a large number of pre-implemented DRL environments and algorithms, making it a comprehensive DRL platform. On this platform,users can further easily manage and tune DRL agents through an interactive training terminal. Evaluation results show that: com-pared to existing DRL libraries, RLzoo not only achieves a high degree of abstraction in its API design. It also provides numerous useful DRL algorithms and environments which are not available in other libraries.\n","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"c5967a74fd45d0f76d15d8220147f41b","permalink":"https://luomai.netlify.app/project/rlzoo/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/project/rlzoo/","section":"project","summary":"A Comprehensive Reinforcement Learning Model Zoo [![GitHub stars](https://img.shields.io/github/stars/tensorlayer/rlzoo.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/tensorlayer/rlzoo/stargazers/)","tags":["Deep Learning"],"title":"RLzoo","type":"project"},{"authors":null,"categories":null,"content":"Deep learning models are trained on servers with many GPUs, and training must scale with the number of GPUs. Systems such as TensorFlow and Caffe2 train models with parallel synchronous stochastic gradient descent: they process a batch of training data at a time, partitioned across GPUs, and average the resulting partial gradients to obtain an updated global model. To fully utilise all GPUs, systems must increase the batch size, which hinders statistical efficiency. Users tune hyper-parameters such as the learning rate to compensate for this, which is complex and model-specific. We introduce Crossbow, a new single-server multi-GPU system for training deep learning models that enables users to freely choose their preferred batch size\u0026mdash;however small\u0026mdash;while scaling to multiple GPUs. Crossbow uses many parallel model replicas and avoids reduced statistical efficiency through a new synchronous training method. We introduce SMA, a synchronous variant of model averaging in which replicas independently explore the solution space with gradient descent, but adjust their search synchronously based on the trajectory of a globally-consistent average model. Crossbow achieves high hardware efficiency with small batch sizes by potentially training multiple model replicas per GPU, automatically tuning the number of replicas to maximise throughput. our experiments show that Crossbow improves the training time of deep learning models on an 8-GPU server by 1.3\u0026ndash;4X compared to TensorFlow.\n","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"91604dd0ac0d85b19aabd81807a95340","permalink":"https://luomai.netlify.app/project/crossbow/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/project/crossbow/","section":"project","summary":"A Scalable System for Deep Learning with Small Batch Sizes [![GitHub stars](https://img.shields.io/github/stars/lsds/crossbow.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/lsds/crossbow/stargazers/)","tags":["Deep Learning"],"title":"CrossBow","type":"project"},{"authors":["Luo Mai","Alexandros Koliousis","Guo Li","Andrei-Octavian Brabete","Peter Pietzuch"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"2b881ac3ec380aa87e2437d60162c356","permalink":"https://luomai.netlify.app/publication/2019-osr-review/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/2019-osr-review/","section":"publication","summary":"Deep learning (DL) systems expose many tuning parameters (“hyper-parameters”) that affect the performance and accuracy of trained models. Increasingly users struggle to configure hyper-parameters, and a substantial portion of time is spent tuning them empirically. We argue that future DL systems should be designed to help manage hyper-parameters. We describe how a distributed DL system can (i) remove the impact of hyper-parameters on both performance and accuracy, thus making it easier to decide on a good setting, and (ii) support more powerful dynamic policies for adapting hyper-parameters, which take monitored training metrics into account. We report results from prototype implementations that show the practicality of DL system designs that are hyper-parameter-friendly.","tags":"","title":"Taming Hyper-parameters in Deep Learning Systems","type":"publication"},{"authors":[],"categories":null,"content":"","date":1543669200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543669200,"objectID":"5bdd4cabffc0f500301ba9c8fec2973a","permalink":"https://luomai.netlify.app/talk/2018-google-devfest/","publishdate":"2018-12-01T13:00:00Z","relpermalink":"/talk/2018-google-devfest/","section":"talk","summary":"TensorLayer: A flexible library for deep learning researchers and developers","tags":[],"title":"Google Developer Festival","type":"talk"},{"authors":["Luo Mai","Kai Zeng","Rahul Potharaju","Le Xu","Shivaram Venkataraman","Paolo Costa","Terry Kim","Saravanan Muthukrishnan","Vamsi Kuppa","Sudheer Dhulipalla","Sriram Rao"],"categories":null,"content":"","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"78143f48499166d71e098a960676c04d","permalink":"https://luomai.netlify.app/publication/2018-vldb-chi/","publishdate":"2018-07-01T00:00:00Z","relpermalink":"/publication/2018-vldb-chi/","section":"publication","summary":"Stream-processing workloads and modern shared cluster environments exhibit high variability and unpredictability. Combined with the large parameter space and the diverse set of user SLOs, this makes modern streaming systems very challenging to statically configure and tune. To address these issues, in this paper we investigate a novel control-plane design, Chi, which supports continuous monitoring and feedback, and enables dynamic re-configuration. Chi leverages the key insight of embedding control-plane messages in the data-plane channels to achieve a low-latency and flexible control plane for stream-processing systems. Chi introduces a new reactive programming model and design mechanisms to asynchronously execute control policies, thus avoiding global synchronization. We show how this allows us to easily implement a wide spectrum of control policies targeting different use cases observed in production. Large-scale experiments using production workloads from a popular cloud provider demonstrate the flexibility and efficiency of our approach.","tags":"","title":"Chi: A Scalable and Programmable Control Plane for Distributed Stream Processing Systems","type":"publication"},{"authors":["Nik Sultana","Salvator Galea","David Greaves","Marcin Wojcik","Jonny Shipton","Richard Clegg","Luo Mai","Pietro Bressana","Robert Soule","Richard Mortier","Paolo Costa","Peter Pietzuch","Jon Crowcroft","Andrew W Moore","Noa Zilberman"],"categories":null,"content":"","date":1501545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501545600,"objectID":"b5e6461c44a15dd286fce83f95e8aee2","permalink":"https://luomai.netlify.app/publication/2017-atc-emu/","publishdate":"2017-08-01T00:00:00Z","relpermalink":"/publication/2017-atc-emu/","section":"publication","summary":"Due to their performance and flexibility, FPGAs are an attractive platform for the execution of network functions. It has been a challenge for a long time though to make FPGA programming accessible to a large audience of developers. An appealing solution is to compile code from a general-purpose language to hardware using high-level synthesis. Unfortunately, current approaches to implement rich network functionality are insufficient because they lack: (i) libraries with abstractions for common network operations and data structures, (ii) bindings to the underlying “substrate” on the FPGA, and (iii) debugging and profiling support. This paper describes Emu, a new standard library for an FPGA hardware compiler that enables developers to rapidly create and deploy network functionality. Emu allows for high-performance designs without being bound to particular packet processing paradigms. Furthermore, it supports running the same programs on CPUs, in Mininet, and on FPGAs, providing a better development environment that includes advanced debugging capabilities. We demonstrate that network functions implemented using Emu have only negligible resource and performance overheads compared with natively-written hardware versions.","tags":"","title":"Emu: Rapid Prototyping of Networking Services","type":"publication"},{"authors":["Hao Dong","Akara Supratak","Luo Mai","Fangde Liu","Axel Oehmichen","Simiao Yu","Yike Guo"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"df83558d9fa95a003b3db9795ca5abf2","permalink":"https://luomai.netlify.app/publication/2017-multimedia-tensorlayer/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publication/2017-multimedia-tensorlayer/","section":"publication","summary":"Recently we have observed emerging uses of deep learning techniques in multimedia systems. Developing a practical deep learning system is arduous and complex. It involves labor-intensive tasks for constructing sophisticated neural networks, coordinating multiple network models, and managing a large amount of training-related data. To facilitate such a development process, we propose TensorLayer which is a Python-based versatile deep learning library. TensorLayer provides high-level modules that abstract sophisticated operations towards neuron layers, network models, training data and dependent training jobs. In spite of offering simplicity, it has transparent module interfaces that allows developers to flexibly embed low-level controls within a backend engine, with the aim of supporting fine-grain tuning towards training. Real-world cluster experiment results show that TensorLayeris able to achieve competitive performance and scalability in critical deep learning tasks. TensorLayer was released in September 2016 on GitHub. Since after, it soon become one of the most popular open-sourced deep learning library used by researchers and practitioners.","tags":"","title":"TensorLayer: A Versatile Library for Efficient Deep Learning Development","type":"publication"},{"authors":["Abdul Alim","Richard G. Clegg","Luo Mai","Lukas Rupprecht","Eric Seckler","Paolo Costa","Peter Pietzuch","Alexander L. Wolf","Nik Sultana","Jon Crowcroft","Anil Madhavapeddy","Andrew Moore","Richard Mortier","Luis Oviedo","Masoud Koleni","Derek McAuley","Matteo Migliavacca"],"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"7cfc2cbb955075a97335eab5c7c29dd6","permalink":"https://luomai.netlify.app/publication/2016-atc-flick/","publishdate":"2016-08-01T00:00:00Z","relpermalink":"/publication/2016-atc-flick/","section":"publication","summary":"Data centre networks are increasingly programmable, with application-specific network services proliferating, from custom load-balancers to middleboxes providing caching and aggregation. Developers must currently implement these services using traditional low-level APIs, which neither support natural operations on application data nor provide efficient performance isolation. We describe FLICK, a framework for the programming and execution of application-specific network services on multi-core CPUs. Developers write network services in the FLICK language, which offers high-level processing constructs and application-relevant data types. FLICK programs are translated automatically to efficient, parallel task graphs, implemented in C++ on top of a user-space TCP stack. Task graphs have bounded resource usage at runtime, which means that the graphs of multiple services can execute concurrently without interference using cooperative scheduling. We evaluate FLICK with several services (an HTTP load-balancer, a Memcached router and a Hadoop data aggregator), showing that it achieves good performance while reducing development effort.","tags":"","title":"Flick: Developing and Running Application-specific Network Services ","type":"publication"},{"authors":["Da Yu","Luo Mai","Somaya Arianfar","Rodrigo Fonseca","Orran Krieger","David Oran"],"categories":null,"content":"","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467331200,"objectID":"8c76da1be60380cb77551e9aa9ddd7cd","permalink":"https://luomai.netlify.app/publication/2016-hotcloud-netex/","publishdate":"2016-07-01T00:00:00Z","relpermalink":"/publication/2016-hotcloud-netex/","section":"publication","summary":"Virtually all public clouds today are run by single providers, and this creates near-monopolies, inefficient markets, and hinders innovation at the infrastructure level. There are current proposals to change this, by creating open architectures that allow providers of computing and storage resources to compete for tenant services at multiple levels, all the way down to the bare metal. Networking, however, is not part of this, and is viewed as a commodity much like power or cooling. In this paper we borrow ideas from the Internet architecture, and propose to structure the cloud datacenter network as a marketplace where multiple service providers can offer connectivity services to tenants. Our marketplace, NetEx, divides the network into independently managed pods of resources, interconnected with multiple providers through special programmable switches that play a role analogous to that of an IXP. We demonstrate the feasibility of such an architecture by a prototype in Mininet, and argue that this can be a way to provide innovation, competition, and efficiency in future cloud datacenter networks.","tags":"","title":"Towards a Network Marketplace in a Cloud","type":"publication"},{"authors":["Luo Mai","Chuntao Hong","Paolo Costa"],"categories":null,"content":"","date":1435708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435708800,"objectID":"b9af09566036effe01693fbd7417c92a","permalink":"https://luomai.netlify.app/publication/2015-hotcloud-mlnet/","publishdate":"2015-07-01T00:00:00Z","relpermalink":"/publication/2015-hotcloud-mlnet/","section":"publication","summary":"To cope with the ever growing availability of training data, there have been several proposals to scale machine learning computation beyond a single server and distribute it across a cluster. While this enables reducing the training time, the observed speed up is often limited by network bottlenecks. To address this, we design MLNET, a host-based communication layer that aims to improve the network performance of distributed machine learning systems. This is achieved through a combination of traffic reduction techniques (to diminish network load in the core and at the edges) and traffic management (to reduce average training time). A key feature of MLNET is its compatibility with existing hardware and software infrastructure so it can be immediately deployed. We describe the main techniques underpinning ML- NET and show through simulation that the overall training time can be reduced by up to 78%. While preliminary, our results indicate the critical role played by the network and the benefits of introducing a new communication layer to increase the performance of distributed machine learning systems.","tags":"","title":"Optimizing Network Performance in Distributed Machine Learning","type":"publication"},{"authors":["Luo Mai","Lukas Rupprecht","Abdul Alim","Paolo Costa","Matteo Migliavacca","Peter Pietzuch","Alexander L. Wolf"],"categories":null,"content":"","date":1417392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417392000,"objectID":"b5afacccb120fcc5840643a1cfe54989","permalink":"https://luomai.netlify.app/publication/2014-conext-netagg/","publishdate":"2014-12-01T00:00:00Z","relpermalink":"/publication/2014-conext-netagg/","section":"publication","summary":"Data centre applications for batch processing (e.g. map/reduce frameworks) and online services (e.g. search engines) scale by distributing data and computation across many servers. They typically follow a partition/aggregation pattern: tasks are first partitioned across servers that process data locally, and then those partial results are aggregated. This data aggregation step, however, shifts the performance bottleneck to the network, which typically struggles to support many-to-few, high-bandwidth traffic between servers. Instead of performing data aggregation at edge servers, we show that it can be done more efficiently along network paths. We describe NETAGG, a software platform that supports on-path aggregation for network-bound partition/aggregation applications. NET-AGG exploits a middlebox-like design, in which dedicated servers (agg boxes) are connected by high-bandwidth links to network switches. Agg boxes execute aggregation functions provided by ap- plications, which alleviates network hotspots because only a fraction of the incoming traffic is forwarded at each hop. NETAGG requires only minimal application changes: it uses shim layers on edge servers to redirect application traffic transparently to the agg boxes. Our experimental results show that NETAGG improves substantially the throughput of two sample applications, the Solr distributed search engine and the Hadoop batch processing framework. Its design allows for incremental deployment in existing data centres and incurs only a modest investment cost.","tags":"","title":"NetAgg: Using Middleboxes for Application-specific On-path Aggregation in Data Centres","type":"publication"},{"authors":["Luo Mai","Evangelia Kalyvianaki","Paolo Costa"],"categories":null,"content":"","date":1385856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385856000,"objectID":"9221ab2bfeabe9c6199812e0827c0b25","permalink":"https://luomai.netlify.app/publication/2013-ladis-mai/","publishdate":"2013-12-01T00:00:00Z","relpermalink":"/publication/2013-ladis-mai/","section":"publication","summary":"Existing cloud provisioning schemes allocate re- sources to batch processing systems at deployment time and only change this allocation at run-time due to unexpected events such as server failures. We observe that MapReduce-like jobs are time- malleable, i.e., at runtime it is possible to dynamically vary the number of resources allocated to a job and, hence, its completion time. In this paper, we propose a novel approach based on time-malleability to opportunistically update job resources in order to increase overall utilization and revenue. To set the right incentives for both providers and tenants, we introduce a novel pricing model that charges tenants according to job completion times. Using this model, we formulate an optimization problem for revenue maximization. Preliminary results show that compared to today’s practices our solution can increase revenue by up to 69.7% and can accept up to 57% more jobs.","tags":"","title":"Exploiting Time-malleability in Cloud-based Batch Processing Systems","type":"publication"},{"authors":["Luo Mai","Longfei Shangguan","Chao Lang","Junzhao Du","Zhenjiang Li","Mo Li"],"categories":null,"content":"","date":1322697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1322697600,"objectID":"a13bae634b4f93dcf87a1cea80752334","permalink":"https://luomai.netlify.app/publication/2011-mass-mai/","publishdate":"2011-12-01T00:00:00Z","relpermalink":"/publication/2011-mass-mai/","section":"publication","summary":"We study the rendezvous data collection problem for the mobile sink in wireless sensor networks. We introduce to jointly optimize trajectory planning for the mobile sink and workload balancing for the network. By doing so, the mobile sink is able to efficiently collect network-wide data within a given delay bound and the network can eliminate the energy bottleneck to dramatically prolong its lifetime. Such a joint optimization problem is shown to be NP-hard and we propose an approximation algorithm, named RPS-LB, to approach the optimal solution. In RPS-LB, according to observed properties of the median reference structure in the network, a series of Rendezvous Points (RPs) are selected to construct the trajectory for the mobile sink and the derived approximation ratio of RPS- LB guarantees that the formed trajectory is comparable with the optimal solution. The workload allocated to each RP is proven to be balanced mathematically. We then relax the assumption that mobile sink knows the location of each sensor node and present a localized, fully distributed version, RPS-LB-D, which largely improves the system applicability in practice. We verify the effectiveness of our proposals via extensive experiments.","tags":"","title":"Load Balanced Rendezvous Data Collection in Wireless Sensor Networks","type":"publication"}]