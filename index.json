[{"authors":["Jie-Ren"],"categories":null,"content":"Jie is collaborating with us on large-scale GPU-based linear system solvers.\n","date":1702598400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1702598400,"objectID":"f8e812c0035dbedbea67c36012073d09","permalink":"https://luomai.github.io/author/jie-ren/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jie-ren/","section":"authors","summary":"Jie is collaborating with us on large-scale GPU-based linear system solvers.","tags":null,"title":"Jie Ren","type":"authors"},{"authors":["Xiulong-Yuan"],"categories":null,"content":"Xiulong is collaborating with us on large-scale graph learning systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"55b5cd5454e5408ed0414f92d767d709","permalink":"https://luomai.github.io/author/xiulong-yuan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xiulong-yuan/","section":"authors","summary":"Xiulong is collaborating with us on large-scale graph learning systems.","tags":null,"title":"Xiulong Yuan","type":"authors"},{"authors":["Zeyuan-Tan"],"categories":null,"content":"Zeyuan was a MScR student working on an open-sourced distributed graph learning system: Quiver. He has joined a leading start-up company Kumo.ai after graduation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3b020c596d71e3cc9302c5da93ecb7ca","permalink":"https://luomai.github.io/author/zeyuan-tan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/zeyuan-tan/","section":"authors","summary":"Zeyuan was a MScR student working on an open-sourced distributed graph learning system: Quiver. He has joined a leading start-up company Kumo.ai after graduation.","tags":null,"title":"Zeyuan Tan","type":"authors"},{"authors":["Chijun-Sima"],"categories":null,"content":" Chijun Sima homepage.\n","date":1667260800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667260800,"objectID":"efa841db90e49dcb035e58a044376ffb","permalink":"https://luomai.github.io/author/chijun-sima/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chijun-sima/","section":"authors","summary":"Chijun Sima homepage.","tags":null,"title":"Chijun Sima","type":"authors"},{"authors":["Leyang-Xue"],"categories":null,"content":" Homepage\n","date":1758844800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1758844800,"objectID":"913c54416bc7c1ba7ae0f64c1568c7a9","permalink":"https://luomai.github.io/author/leyang-xue/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/leyang-xue/","section":"authors","summary":"Homepage","tags":null,"title":"Leyang Xue","type":"authors"},{"authors":["Man-Kit-Sit"],"categories":null,"content":"","date":1758844800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1758844800,"objectID":"fc23037b1605cd04a6e0178f37fbbd1d","permalink":"https://luomai.github.io/author/man-kit-sit/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/man-kit-sit/","section":"authors","summary":"","tags":null,"title":"Man-Kit Sit","type":"authors"},{"authors":["Yao-Fu"],"categories":null,"content":" Homepage\n","date":1758844800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1758844800,"objectID":"1c71ea3d26c0b0a01eaa178d034b647b","permalink":"https://luomai.github.io/author/yao-fu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yao-fu/","section":"authors","summary":"Homepage","tags":null,"title":"Yao Fu","type":"authors"},{"authors":["Congejie-He"],"categories":null,"content":"Congjie He is a PhD student in the School of Informatics at the University of Edinburgh. His research focuses on building AI training and inference infrastructure in large-scale distributed memory architectures, such as the Cerebras WSE-3 and GPU Super-Pods, and involves the co-design of models, systems, and hardware. He is also the leading author of WaferLLM, and his research has been published in conferences such as OSDI, NeurIPS, and ICML.\n","date":1758844800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1758844800,"objectID":"cc0767cd28edfd47e2f2f826d6c2c59d","permalink":"https://luomai.github.io/author/congjie-he/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/congjie-he/","section":"authors","summary":"Congjie He is a PhD student in the School of Informatics at the University of Edinburgh. His research focuses on building AI training and inference infrastructure in large-scale distributed memory architectures, such as the Cerebras WSE-3 and GPU Super-Pods, and involves the co-design of models, systems, and hardware.","tags":null,"title":"Congjie He","type":"authors"},{"authors":["Yeqi-Huang"],"categories":null,"content":"Yeqi Huang is a PhD student at the Edinburgh-AISys Group, specializing in AI systems. His research focuses on enhancing system capabilities for large-scale AI training and inference, particularly on Spatial Architecture AI chips such as TPU and Cerebras. With a background in High Performance Computing, Yeqi is also an active open-source developer who enjoys hackathons and sharing projects on GitHub.\nHomepage\n","date":1758844800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1758844800,"objectID":"6d08feedb04ffb7b2faac0a2e75fd1e6","permalink":"https://luomai.github.io/author/yeqi-huang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yeqi-huang/","section":"authors","summary":"Yeqi Huang is a PhD student at the Edinburgh-AISys Group, specializing in AI systems. His research focuses on enhancing system capabilities for large-scale AI training and inference, particularly on Spatial Architecture AI chips such as TPU and Cerebras.","tags":null,"title":"Yeqi Huang","type":"authors"},{"authors":["Maria-Durackova"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"663996e5e2ae1c9efe067764b631598c","permalink":"https://luomai.github.io/author/maria-durackova/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/maria-durackova/","section":"authors","summary":"","tags":null,"title":"Maria Durackova","type":"authors"},{"authors":["Matej-Sandor"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e625236ca351a52100a30c5dace0e74e","permalink":"https://luomai.github.io/author/matej-sandor/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/matej-sandor/","section":"authors","summary":"","tags":null,"title":"Matej Sandor","type":"authors"},{"authors":["Xuan-Sun"],"categories":null,"content":"Xuan Sun is a Research Associate working with Prof. Boris Grot and me. She joined us in 2024 from Imperial College London, where she also held a Research Associate position.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"5d1efeafcb465234de6185f1ac8bc677","permalink":"https://luomai.github.io/author/xuan-sun/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xuan-sun/","section":"authors","summary":"Xuan Sun is a Research Associate working with Prof. Boris Grot and me. She joined us in 2024 from Imperial College London, where she also held a Research Associate position.","tags":null,"title":"Xuan Sun","type":"authors"},{"authors":["Dayou-Du"],"categories":null,"content":"","date":1758844800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1758844800,"objectID":"7d6044dd6e229b9d66da0482143a104c","permalink":"https://luomai.github.io/author/dayou-du/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dayou-du/","section":"authors","summary":"","tags":null,"title":"Dayou Du","type":"authors"},{"authors":["Zhan-Lu"],"categories":null,"content":"","date":1758844800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1758844800,"objectID":"2cfd7e7b0b09afe1fd5651e396442f38","permalink":"https://luomai.github.io/author/zhan-lu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/zhan-lu/","section":"authors","summary":"","tags":null,"title":"Zhan Lu","type":"authors"},{"authors":["Cheng-Deng"],"categories":null,"content":"Cheng Deng is currently a Bayes Centre Research Fellow. He joined us in 2025 from the London Huawei Research Lab, where he worked as a Research Scientist. His homepage can be found here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e1403325d559be7850b369e6990bbd10","permalink":"https://luomai.github.io/author/cheng-deng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/cheng-deng/","section":"authors","summary":"Cheng Deng is currently a Bayes Centre Research Fellow. He joined us in 2025 from the London Huawei Research Lab, where he worked as a Research Scientist. His homepage can be found here.","tags":null,"title":"Cheng Deng","type":"authors"},{"authors":["Haocheng-Xiao"],"categories":null,"content":"Haocheng Xiao is a Research Associate working on the ARIA project. He joined our group after completing his PhD at the University of Edinburgh. His homepage is available here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"eddb39e30997371f03582b8aed473fe0","permalink":"https://luomai.github.io/author/haocheng-xiao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/haocheng-xiao/","section":"authors","summary":"Haocheng Xiao is a Research Associate working on the ARIA project. He joined our group after completing his PhD at the University of Edinburgh. His homepage is available here.","tags":null,"title":"Haocheng Xiao","type":"authors"},{"authors":["Yi-Chieh-Wang"],"categories":null,"content":"YiChieh Wang is a PhD student at the University of Edinburgh supervised by Prof. Luo Mai. His current research focuses on hardware design for AI, particularly on network-on-chip architectures for large-scale AI accelerators. He previously worked at TSMC and Cadence, gaining hands-on experience in lithography processes and physical design.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e03b8d839839b039e610337a679660f2","permalink":"https://luomai.github.io/author/yi-chieh-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yi-chieh-wang/","section":"authors","summary":"YiChieh Wang is a PhD student at the University of Edinburgh supervised by Prof. Luo Mai. His current research focuses on hardware design for AI, particularly on network-on-chip architectures for large-scale AI accelerators.","tags":null,"title":"Yi-Chieh Wang","type":"authors"},{"authors":["Yinsicheng-Jiang"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d86a6170360c4e67aaa949cad8453e21","permalink":"https://luomai.github.io/author/yinsicheng-jiang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yinsicheng-jiang/","section":"authors","summary":"","tags":null,"title":"Yinsicheng Jiang","type":"authors"},{"authors":["Tairan-Xu"],"categories":null,"content":"","date":1758844800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1758844800,"objectID":"82c023b8f15a1cd3985274f41f2bd70b","permalink":"https://luomai.github.io/author/tairan-xu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/tairan-xu/","section":"authors","summary":"","tags":null,"title":"Tairan Xu","type":"authors"},{"authors":["Yangsheng-Deng"],"categories":null,"content":" Yangsheng\u0026rsquo;s Homepage\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2472e9ed4b771535147e64144acc75ee","permalink":"https://luomai.github.io/author/yangsheng-deng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yangsheng-deng/","section":"authors","summary":"Yangsheng\u0026rsquo;s Homepage","tags":null,"title":"Yangsheng Deng","type":"authors"},{"authors":["admin"],"categories":null,"content":"I am a Reader (Associate Professor) in the School of Informatics at the University of Edinburgh, where I lead the Large-Scale Machine Learning Systems Group. I also co-lead the UK EPSRC Centre for Doctoral Training in Machine Learning Systems and the ARIA Project on Scaling AI Compute by 1000X.\nMy research group works across the full stack of AI systems \u0026ndash; from models to software and systems \u0026ndash; pursuing co-designs that can drive a 1000X leap in efficiency and scalability of AI systems. My research has been recognized with awards and rising-star honours from academia and industry. I co-edited the open-source textbook Machine Learning Systems: Design and Implementation and co-founded open-source AI system libraries that have collectively received over 20,000 GitHub stars.\nBefore joining Edinburgh, I was a Research Associate at Imperial College London, working with Peter Pietzuch, and a Visiting Researcher at Microsoft Research. My PhD, supervised by Paolo Costa and Alexander L. Wolf, was supported by a Google Fellowship in Cloud Computing.\n","date":1758844800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1758844800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://luomai.github.io/author/luo-mai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/luo-mai/","section":"authors","summary":"I am a Reader (Associate Professor) in the School of Informatics at the University of Edinburgh, where I lead the Large-Scale Machine Learning Systems Group. I also co-lead the UK EPSRC Centre for Doctoral Training in Machine Learning Systems and the ARIA Project on Scaling AI Compute by 1000X.","tags":null,"title":"Luo Mai","type":"authors"},{"authors":["Marcel-Wagenlander"],"categories":null,"content":"Marcel did a research project \u0026ldquo;Large-scale training of the Google BERT model\u0026rdquo; at Imperial College London in 2020. His project has led to a paper \u0026ldquo;Spotnik: Designing Distributed Machine Learning for Transient Cloud Resources\u0026rdquo; accepted by a leading system workshop: USENIX HotCloud 2020. Marcel started as a PhD student at Imperial College London afterwards.\n","date":1721952000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1721952000,"objectID":"b906b9ad100240ef5914119e4e019158","permalink":"https://luomai.github.io/author/marcel-wagenlander/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/marcel-wagenlander/","section":"authors","summary":"Marcel did a research project \u0026ldquo;Large-scale training of the Google BERT model\u0026rdquo; at Imperial College London in 2020. His project has led to a paper \u0026ldquo;Spotnik: Designing Distributed Machine Learning for Transient Cloud Resources\u0026rdquo; accepted by a leading system workshop: USENIX HotCloud 2020.","tags":null,"title":"Marcel Wagenlander","type":"authors"},{"authors":["Andrei-Octavian-Brabete"],"categories":null,"content":"Andrei did his MEng project \u0026ldquo;Kungfu: A Novel Distributed Training System for TensorFlow using Flexible Synchronisation\u0026rdquo; at Imperial College London in 2019. His project received a Distinguished Project Award as well as a Departmental Price for Excellence. There are only 3 students who can receive these two awards at a time in 2019. Andrei joined G-Research after graduation.\n","date":1706227200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1706227200,"objectID":"789243ef38d81e10fc09b683a5129c67","permalink":"https://luomai.github.io/author/andrei-octavian-brabete/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/andrei-octavian-brabete/","section":"authors","summary":"Andrei did his MEng project \u0026ldquo;Kungfu: A Novel Distributed Training System for TensorFlow using Flexible Synchronisation\u0026rdquo; at Imperial College London in 2019. His project received a Distinguished Project Award as well as a Departmental Price for Excellence.","tags":null,"title":"Andrei-Octavian Brabete","type":"authors"},{"authors":["Jiawei-Liu"],"categories":null,"content":"Jiawei visited my group from 2020 - 2021, working on high-performance computer vision systems. His project has led to a popular open-source library: HyperPose, and a paper accepted to ACM Multimedia 2021. Jiawei is pursuing his PhD at the University of Illinois at Urbana Champaign (UIUC).\n","date":1628985600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1628985600,"objectID":"ce97fd581d7e2429725dc1930d3a115e","permalink":"https://luomai.github.io/author/jiawei-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jiawei-liu/","section":"authors","summary":"Jiawei visited my group from 2020 - 2021, working on high-performance computer vision systems. His project has led to a popular open-source library: HyperPose, and a paper accepted to ACM Multimedia 2021.","tags":null,"title":"Jiawei Liu","type":"authors"},{"authors":["Guanqi-Zhan"],"categories":null,"content":"Guanqi visited my group in 2019 and acted as a key developer for TensorLayer. His research work has been accepted to leading ML venues such as NeurIPS. Guanqi is pursuing his PhD in machine learning and computer vision at the University of Oxford.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bdbdceb8c2eccbcedaf9af5b01fa5383","permalink":"https://luomai.github.io/author/guanqi-zhan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/guanqi-zhan/","section":"authors","summary":"Guanqi visited my group in 2019 and acted as a key developer for TensorLayer. His research work has been accepted to leading ML venues such as NeurIPS. Guanqi is pursuing his PhD in machine learning and computer vision at the University of Oxford.","tags":null,"title":"Guanqi Zhan","type":"authors"},{"authors":["Ioan-Budea"],"categories":null,"content":"Ioan did his MEng project \u0026ldquo;TensorBow: Supporting Small-Batch Training in TensorFlow\u0026rdquo; at Imperial College London in 2019. His project received a Distinguished Project Award as well as a Departmental Price for Excellence. There are only 3 students who can receive these two awards at a time in 2019. Ioan joined Facebook after graduation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3bb2df6388766214ff822961b1d87ac3","permalink":"https://luomai.github.io/author/ioan-budea/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ioan-budea/","section":"authors","summary":"Ioan did his MEng project \u0026ldquo;TensorBow: Supporting Small-Batch Training in TensorFlow\u0026rdquo; at Imperial College London in 2019. His project received a Distinguished Project Award as well as a Departmental Price for Excellence.","tags":null,"title":"Ioan Budea","type":"authors"},{"authors":["Yinsicheng Jiang *","Yao Fu","Yeqi Huang","Ping Nie","Zhan Lu","Leyang Xue","Congjie He","Man-Kit Sit","Jilong Xue","Li Dong","Ziming Miao","Dayou Du","Tairan Xu","Kai Zou","Edoardo Ponti","Luo Mai"],"categories":null,"content":"","date":1758844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1758844800,"objectID":"a10915a797d67799b0db721894d9abbe","permalink":"https://luomai.github.io/publication/2025-neurips-moecap/","publishdate":"2025-09-26T00:00:00Z","relpermalink":"/publication/2025-neurips-moecap/","section":"publication","summary":"The sparse Mixture-of-Experts (MoE) architecture is increasingly favored for scaling Large Language Models (LLMs) efficiently, but it depends on heterogeneous compute and memory resources. These factors jointly affect system Cost, Accuracy, and Performance (CAP), making trade-offs inevitable. Existing benchmarks often fail to capture these trade-offs accurately, complicating practical deployment decisions. To address this, we introduce MoE-CAP, a benchmark specifically designed for MoE systems. Our analysis reveals that achieving an optimal balance across CAP is difficult with current hardware; MoE systems typically optimize two of the three dimensions at the expense of the third-a dynamic we term the MoE-CAP trade-off. To visualize this, we propose the CAP Radar Diagram. We further introduce sparsity-aware performance metrics-Sparse Memory Bandwidth Utilization (S-MBU) and Sparse Model FLOPS Utilization (S-MFU)-to enable accurate performance benchmarking of MoE systems across diverse hardware platforms and deployment scenarios.","tags":["Machine Learning Systems"],"title":"MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems","type":"publication"},{"authors":[],"categories":[],"content":"","date":1758803737,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1758803737,"objectID":"c3a3e497ab937b7962dbbf1f025c5231","permalink":"https://luomai.github.io/post/25-moecap-neurips/","publishdate":"2025-09-25T13:35:37+01:00","relpermalink":"/post/25-moecap-neurips/","section":"post","summary":"","tags":[],"title":"[09/25, Paper] MoE-CAP accepted to NeurIPS 2025 (Dataset and Benchmark Track).","type":"post"},{"authors":[],"categories":[],"content":"Excited to share that our SketchPad project has been selected by the AI4Math fund to advance breakthroughs in mathematics! I’ll contribute my expertise in building large-scale, efficient, and reliable AI systems. The project is led by Wenda Li, together with Huajian Xin, Lawrence C. Paulson, and me.\nThanks to this generous support, we will be hiring several fully funded PhD students and Postdoctoral researchers. If you are passionate about pushing AI to tackle high-impact mathematical problems and other game-changing scientific discovery challenges, we’d love to hear from you.\n","date":1756125337,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756125337,"objectID":"ae4295c7d70316cf62422c462bc85470","permalink":"https://luomai.github.io/post/25-ai4math/","publishdate":"2025-08-25T13:35:37+01:00","relpermalink":"/post/25-ai4math/","section":"post","summary":"Excited to share that our SketchPad project has been selected by the AI4Math fund to advance breakthroughs in mathematics! I’ll contribute my expertise in building large-scale, efficient, and reliable AI systems.","tags":[],"title":"[08/25, Grant] Win a prestigious award to build systems for powering AI4Math breakthroughs.","type":"post"},{"authors":[],"categories":[],"content":"Emerging AI accelerators increasingly adopt wafer-scale manufacturing technologies, integrating hundreds of thousands of AI cores in a mesh architecture with large distributed on-chip memory (tens of GB in total) and ultra-high on-chip memory bandwidth (tens of PB/s). However, current LLM inference systems, optimized for shared memory architectures like GPUs, fail to exploit these accelerators fully.\nWe introduce WaferLLM, the first wafer-scale LLM inference system. WaferLLM is guided by a novel PLMR model (pronounced as \u0026ldquo;Plummer\u0026rdquo;) that captures the unique hardware characteristics of wafer-scale architectures. Leveraging this model, WaferLLM pioneers wafer-scale LLM parallelism, optimizing the utilization of hundreds of thousands of on-chip cores. It also introduces MeshGEMM and MeshGEMV, the first GEMM and GEMV implementations designed to scale effectively on wafer-scale accelerators.\nEvaluations show that WaferLLM achieves up to 200× higher accelerator utilization than state-of-the-art methods. Leveraging a wafer-scale accelerator (Cerebras WSE2), WaferLLM delivers GEMV operations 606× faster and 16× more energy-efficient than on an NVIDIA A100 GPU. For full LLM inference, WaferLLM achieves 10-20× speedups over A100 GPU clusters running SGLang and vLLM. These advantages are expected to grow as wafer-scale AI models, software, and hardware continue to mature. WaferLLM is open-sourced at: https://github.com/MeshInfra/WaferLLM\n","date":1751373337,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751373337,"objectID":"d0eb21b645122a378194813568eb3920","permalink":"https://luomai.github.io/post/25-waferllm-osdi/","publishdate":"2025-07-01T13:35:37+01:00","relpermalink":"/post/25-waferllm-osdi/","section":"post","summary":"Emerging AI accelerators increasingly adopt wafer-scale manufacturing technologies, integrating hundreds of thousands of AI cores in a mesh architecture with large distributed on-chip memory (tens of GB in total) and ultra-high on-chip memory bandwidth (tens of PB/s).","tags":[],"title":"[07/25, Paper] WaferLLM, the world fastest LLM inference system, accepted to OSDI 2025.","type":"post"},{"authors":["Congjie He","Yeqi Huang","Pei Mu","Ziming Miao","Jilong Xue","Lingxiao Ma","Fan Yang","Luo Mai"],"categories":null,"content":"","date":1742947200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1742947200,"objectID":"d1f38dccdecc7b12a09b12575fc333da","permalink":"https://luomai.github.io/publication/2025-osdi-waferllm/","publishdate":"2025-03-26T00:00:00Z","relpermalink":"/publication/2025-osdi-waferllm/","section":"publication","summary":"Emerging AI accelerators increasingly adopt wafer-scale manufacturing technologies, integrating hundreds of thousands of AI cores in a mesh architecture with large distributed on-chip memory (tens of GB in total) and ultra-high on-chip memory bandwidth (tens of PB/s). However, current LLM inference systems, optimized for shared memory architectures like GPUs, fail to exploit these accelerators fully. We introduce WaferLLM, the first wafer-scale LLM inference system. WaferLLM is guided by a novel PLMR model (pronounced as Plummer) that captures the unique hardware characteristics of wafer-scale architectures. Leveraging this model, WaferLLM pioneers wafer-scale LLM parallelism, optimizing the utilization of hundreds of thousands of on-chip cores. It also introduces MeshGEMM and MeshGEMV, the first GEMM and GEMV implementations designed to scale effectively on wafer-scale accelerators.Evaluations show that WaferLLM achieves up to 200× higher accelerator utilization than state-of-the-art methods. Leveraging a wafer-scale accelerator (Cerebras WSE2), WaferLLM delivers GEMV operations 606× faster and 16× more energy-efficient than on an NVIDIA A100 GPU. For full LLM inference, WaferLLM achieves 10-20× speedups over A100 GPU clusters running SGLang and vLLM. These advantages are expected to grow as wafer-scale AI models, software, and hardware continue to mature. WaferLLM is open-sourced on GitHub.","tags":["Machine Learning Systems"],"title":"WaferLLM: Large Language Model Inference at Wafer Scale","type":"publication"},{"authors":[],"categories":[],"content":"After nearly five years at Edinburgh, I’m delighted to share that my promotion has been approved, and I will take up the role of Reader (Associate Professor) in August 2025. Sincere thanks to all my students and postdocs, my collaborators around the world, and my colleagues at the School of Informatics, EPCC, and the University for their support along the way.\n","date":1742906137,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1742906137,"objectID":"e47aeea99ea1d9b1bf8ac71879d4553a","permalink":"https://luomai.github.io/post/25-reader-promotion/","publishdate":"2025-03-25T13:35:37+01:00","relpermalink":"/post/25-reader-promotion/","section":"post","summary":"After nearly five years at Edinburgh, I’m delighted to share that my promotion has been approved, and I will take up the role of Reader (Associate Professor) in August 2025. Sincere thanks to all my students and postdocs, my collaborators around the world, and my colleagues at the School of Informatics, EPCC, and the University for their support along the way.","tags":[],"title":"[03/25, Achievement] Starting August 2025, I’ll be Reader (Associate Professor).","type":"post"},{"authors":[],"categories":[],"content":"I am deeply honored to receive a prestigious grant from the Advanced Research + Invention Agency (ARIA) to develop a scalable and modular performance simulation framework for emerging AI models, systems, and hardware. This project will be co-led by Imperial (Aaron Zhao), Edinburgh (Luo Mai), and Cambridge (Robert Mullins), bringing together over 10 world-leading experts across the entire system stack. With this £4.5M funding, we will build a critical mass of talent and skills to incubate game-changing AI systems, enabling a 1000X improvement in AI\u0026rsquo;s efficiency.\nSee the official announcement from ARIA.\n","date":1729946137,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729946137,"objectID":"17794282a0ebd8a4377f55a09abf47dc","permalink":"https://luomai.github.io/post/24-aria-award/","publishdate":"2024-10-26T13:35:37+01:00","relpermalink":"/post/24-aria-award/","section":"post","summary":"I am deeply honored to receive a prestigious grant from the Advanced Research + Invention Agency (ARIA) to develop a scalable and modular performance simulation framework for emerging AI models, systems, and hardware.","tags":[],"title":"[10/24, Grant] Secured a prestigious ARIA grant with Imperial College \u0026 Cambridge University.","type":"post"},{"authors":[],"categories":[],"content":"Tenplex is a new system enabling elastic training of LLMs with advanced multi-dimensional parallelism. The Tenplex paper has been accepted for presentation at the 30th Symposium on Operating Systems Principles (SOSP’24). We are currently preparing to open-source the project. Stay tuned.\n","date":1729859737,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729859737,"objectID":"bd6485eaca77bc795dd5228a3874b97d","permalink":"https://luomai.github.io/post/24-tenplex-sosp/","publishdate":"2024-10-25T13:35:37+01:00","relpermalink":"/post/24-tenplex-sosp/","section":"post","summary":"Tenplex is a new system enabling elastic training of LLMs with advanced multi-dimensional parallelism. The Tenplex paper has been accepted for presentation at the 30th Symposium on Operating Systems Principles (SOSP’24).","tags":[],"title":"[10/24, Paper] Tenplex, the first elastic LLM system, accepted to SOSP 2024.","type":"post"},{"authors":null,"categories":null,"content":"ServerlessLLM is an open-source framework dedicated to making custom LLM deployment easy, fast, and affordable. As models grow in size and complexity, deploying them on distributed GPUs has become increasingly costly and technically challenging, limiting the benefits of custom LLM deployment to only a select few. ServerlessLLM tackles these challenges by a full-stack, LLM-centric serverless system design, integrating multiple LLM-optimized layers—from checkpoint formats and inference runtimes to the storage layer and cluster scheduler.\n","date":1727740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727740800,"objectID":"41a11900f286639fedd47c85ba55a775","permalink":"https://luomai.github.io/project/serverlessllm/","publishdate":"2024-10-01T00:00:00Z","relpermalink":"/project/serverlessllm/","section":"project","summary":"Serverless LLM serving for everyone. [![GitHub stars](https://img.shields.io/github/stars/ServerlessLLM/ServerlessLLM.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/ServerlessLLM/ServerlessLLM/stargazers/)","tags":null,"title":"ServerlessLLM","type":"project"},{"authors":[],"categories":[],"content":"This year’s Rising Stars cohort includes 41 junior researchers from 33 institutions globally. Selected from over 170 applicants, Yao is the sole recipient from the UK and one of three from Europe, the other two European students coming from ETH, Zurich.\nThe 2024 Rising Start workshop was held in the NVIDIA HQ in Santa Clara, CA in July, where Yao presented his research.\nYao is a third-year PhD student in Computer Science at The University of Edinburgh, supervised by Dr Luo Mai. His research lies at the intersection of machine learning and systems, focusing on performance and affordability. Recently, his work has centred on efficient serving systems for large language models, leading to two main projects: ServerlessLLM and the MoESys Leaderboard.\nSee the coverage from our school and the annoucement from MLCommon.\n","date":1723293337,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1723293337,"objectID":"a2fa1204925c3a6bf034328368f185cd","permalink":"https://luomai.github.io/post/24-risingstar-yao/","publishdate":"2024-08-10T13:35:37+01:00","relpermalink":"/post/24-risingstar-yao/","section":"post","summary":"This year’s Rising Stars cohort includes 41 junior researchers from 33 institutions globally. Selected from over 170 applicants, Yao is the sole recipient from the UK and one of three from Europe, the other two European students coming from ETH, Zurich.","tags":[],"title":"[07/24, Student Achievement] Congrats to Yao Fu on Winning 2024 Rising Star in ML \u0026 Systems.","type":"post"},{"authors":["Marcel Wagenlander","Guo Li","Bo Zhao","Luo Mai","Peter Pietzuch"],"categories":null,"content":"","date":1721952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1721952000,"objectID":"244369910bceb533d26d4819ec4d0678","permalink":"https://luomai.github.io/publication/2024-sosp-tenplex/","publishdate":"2024-07-26T00:00:00Z","relpermalink":"/publication/2024-sosp-tenplex/","section":"publication","summary":"Deep learning (DL) jobs use multi-dimensional parallelism, i.e. combining data, model, and pipeline parallelism, to use large GPU clusters efficiently. Long-running jobs may experience changes to their GPU allocation: (i) resource elasticity during training adds or removes GPUs; (ii) hardware maintenance may require redeployment on different GPUs; and (iii) GPU failures force jobs to run with fewer devices. Current DL frameworks tie jobs to a set of GPUs and thus lack support for these scenarios. In particular, they cannot change the multi-dimensional parallelism of an already-running job in an efficient and model-independent way. We describe Scalai, a state management library for DL systems that enables jobs to change their parallelism dynamically after the GPU allocation is updated at runtime. Scalai achieves this through a new abstraction, a parallelizable tensor collection (PTC), that externalizes the job state during training. After a GPU change, Scalai uses the PTC to transform the job state: the PTC repartitions the dataset state under data parallelism and exposes it to DL workers through a virtual file system; and the PTC obtains the model state as partitioned checkpoints and transforms them to reflect the new parallelization configuration. For efficiency, Scalai executes PTC transformations in parallel with minimum data movement between workers. Our experiments show that Scalai enables DL jobs to support dynamic parallelization with low overhead.","tags":["Machine Learning Systems"],"title":"Tenplex: Dynamic Parallelism for Deep Learning using Parallelizable Tensor Collections","type":"publication"},{"authors":[],"categories":[],"content":"ServerlessLLM is a new system enabling cost-effective serverless inference for LLMs by implementing a scalable and high-performance “checkpoint storage layer” on GPU servers. It achieves this through an innovative LLM checkpoint format, a multi-tier checkpoint loading subsystem, an efficient live migration algorithm, and a locality-friendly GPU serverless architecture.\nThe ServerlessLLM paper has been accepted to the top systems conference, OSDI’24, and we are preparing to open-source the project. Stay tuned.\n","date":1720614937,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720614937,"objectID":"69dd25a0b847711fef85e9aa7c5baff9","permalink":"https://luomai.github.io/post/24-serverlessllm-osdi/","publishdate":"2024-07-10T13:35:37+01:00","relpermalink":"/post/24-serverlessllm-osdi/","section":"post","summary":"ServerlessLLM is a new system enabling cost-effective serverless inference for LLMs by implementing a scalable and high-performance “checkpoint storage layer” on GPU servers. It achieves this through an innovative LLM checkpoint format, a multi-tier checkpoint loading subsystem, an efficient live migration algorithm, and a locality-friendly GPU serverless architecture.","tags":[],"title":"[07/24, Paper] ServerlessLLM, the first serverless LLM system, accepted to OSDI 2024.","type":"post"},{"authors":["Chuanhao Sun","Zhihang Yuan","Kai Xu","Luo Mai","N Siddharth","Shuo Chen","Mahesh K Marina"],"categories":null,"content":"","date":1717200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717200000,"objectID":"527ff9e71b81c70db469b28233396f4a","permalink":"https://luomai.github.io/publication/2024-icml-spe/","publishdate":"2024-06-01T00:00:00Z","relpermalink":"/publication/2024-icml-spe/","section":"publication","summary":" Fourier features based positional encoding (PE) is commonly used in machine learning tasks that involve learning high-frequency features from low-dimensional inputs, such as 3D view synthesis and time series regression with neural tangent kernels. Despite their effectiveness, existing PEs require manual, empirical adjustment of crucial hyperparameters, specifically the Fourier features, tailored to each unique task. Further, PEs face challenges in efficiently learning high-frequency functions, particularly in tasks with limited data. In this paper, we introduce sinusoidal PE (SPE), designed to efficiently learn adaptive frequency features closely aligned with the true underlying function. Our experiments demonstrate that SPE, without hyperparameter tuning, consistently achieves enhanced fidelity and faster training across various tasks, including 3D view synthesis, Text-to-Speech generation, and 1D regression. SPE is implemented as a direct replacement for existing PEs. Its plug-and-play nature lets numerous tasks easily adopt and benefit from SPE.","tags":["Machine Learning Systems"],"title":"Learning high-frequency functions made easy with sinusoidal positional encoding","type":"publication"},{"authors":[],"categories":[],"content":"I am thrilled to receive the Microsoft Research Startrack Scholar Award, a prestigious honor for young faculty in the field of computer science.\n","date":1715344537,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715344537,"objectID":"974f3075ae7cb7499b35ca7eb6b10778","permalink":"https://luomai.github.io/post/24-startrack-microsoft/","publishdate":"2024-05-10T13:35:37+01:00","relpermalink":"/post/24-startrack-microsoft/","section":"post","summary":"I am thrilled to receive the Microsoft Research Startrack Scholar Award, a prestigious honor for young faculty in the field of computer science.","tags":[],"title":"[05/24, Award] Win a Microsoft Research Startrack Scholar Award.","type":"post"},{"authors":["Yao Fu","Leyang Xue","Yeqi Huang","Andrei-Octavian Brabete","Dmitrii Ustiugov","Yuvraj Patel","Luo Mai"],"categories":null,"content":"","date":1706227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706227200,"objectID":"00bfeb401e4c42105dbfde14eaab4861","permalink":"https://luomai.github.io/publication/2024-osdi-serverlessllm/","publishdate":"2024-01-26T00:00:00Z","relpermalink":"/publication/2024-osdi-serverlessllm/","section":"publication","summary":"This paper presents ServerlessLLM, a locality-enhanced serverless inference system for Large Language Models (LLMs). ServerlessLLM exploits the substantial capacity and bandwidth of storage and memory devices available on GPU servers, thereby reducing costly remote checkpoint downloads and achieving efficient checkpoint loading. ServerlessLLM achieves this through three main contributions: (i) fast LLM checkpoint loading via a novel loading-optimized checkpoint format design, coupled with an efficient multi-tier checkpoint loading system; (ii) locality-driven LLM inference with live migration, which allows ServerlessLLM to effectively achieve locality-driven server allocation while preserving the low latency of ongoing LLM inference; and (iii) locality-aware server allocation, enabling ServerlessLLM to evaluate the status of each server in a cluster and effectively schedule model startup time to capitalize on local checkpoint placement. Our comprehensive experiments, which include microbenchmarks and real-world traces, show that ServerlessLLM surpasses state-of-the-art systems by 10 - 200X in latency performance when running various LLM inference workloads.","tags":["Machine Learning Systems"],"title":"ServerlessLLM: Low-Latency Serverless Inference for Large Language Models","type":"publication"},{"authors":[],"categories":[],"content":"I am deeply thrilled to have secured an EPSRC grant (£8.7M) matched with £9.2M from industry partners to establish a Centre for Doctoral Training (CDT) in ML Systems. This grant is co-led by Amos Storkey (PI), Mike O\u0026rsquo;Boyle (co-I), Ajitha Rajan (co-I), and myself (co-I). With this CDT, we are one of the few places in the world capable of creating the critical mass of talent, skills, and resources needed to incubate game-changing technologies for ML systems.\nThrough this CDT, PhD students will have the opportunity to build expertise across the entire AI system stack—spanning models, algorithms, software, hardware, and large-scale clusters. The CDT is supported by UK EPSRC and over 20 industry partners, with that number still growing.\nSee the announcement 1 and announcement 2 from EPSRC.\n","date":1705754137,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705754137,"objectID":"96c21833baa35cbcb27d2a77d1c13e34","permalink":"https://luomai.github.io/post/24-mlsyscdt-award/","publishdate":"2024-01-20T13:35:37+01:00","relpermalink":"/post/24-mlsyscdt-award/","section":"post","summary":"I am deeply thrilled to have secured an EPSRC grant (£8.7M) matched with £9.2M from industry partners to establish a Centre for Doctoral Training (CDT) in ML Systems. This grant is co-led by Amos Storkey (PI), Mike O\u0026rsquo;Boyle (co-I), Ajitha Rajan (co-I), and myself (co-I).","tags":[],"title":"[03/24, Grant] Secured funds from EPSRC and industry partners to build a CDT for ML Systems.","type":"post"},{"authors":["Jie Ren","Xidong Feng*","Bo Liu*","Xuehai Pan*","Yao Fu","Luo Mai","Yaodong Yang"],"categories":null,"content":"","date":1702598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702598400,"objectID":"a0e9bde742e4a95f0cad1d267656fd80","permalink":"https://luomai.github.io/publication/2023-jmlr-torchopt/","publishdate":"2023-12-15T00:00:00Z","relpermalink":"/publication/2023-jmlr-torchopt/","section":"publication","summary":"Differentiable optimization algorithms often involve expensive computations of various meta-gradients. To address this, we design and implement TorchOpt, a new PyTorch-based differentiable optimization library. TorchOpt provides an expressive and unified program- ming interface that simplifies the implementation of explicit, implicit, and zero-order gradients. Moreover, TorchOpt has a distributed execution runtime capable of parallelizing diverse operations linked to differentiable optimization tasks across CPU and GPU devices. Experimental results demonstrate that TorchOpt achieves a 5.2× training time speedup in a cluster. TorchOpt is open-sourced at https://github.com/metaopt/torchopt and has become a PyTorch Ecosystem project.","tags":["Machine Learning Systems"],"title":"TorchOpt: An Efficient Library for Differentiable Optimization","type":"publication"},{"authors":[],"categories":[],"content":"After 2 years incubation, TorchOpt has become a PyTorch Ecosystem Project Announcement. Its paper is also accepted by the JMLR in the open-source software track.\n","date":1702211737,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702211737,"objectID":"0ff4ad0ebfab7a05ed0aa30446865889","permalink":"https://luomai.github.io/post/23-torchopt-jmlr/","publishdate":"2023-12-10T13:35:37+01:00","relpermalink":"/post/23-torchopt-jmlr/","section":"post","summary":"After 2 years incubation, TorchOpt has become a PyTorch Ecosystem Project Announcement. Its paper is also accepted by the JMLR in the open-source software track.","tags":[],"title":"[12/23, Paper \u0026 Award] TorchOpt is accepted by JMLR and becomes a PyTorch Ecosystem Project.","type":"post"},{"authors":[],"categories":[],"content":"I am nominated by the school for a Chancellor\u0026rsquo;s Rising Star in Research Award, a prestigious honour for young faculty joined University of Edinburgh between 2018 and 2023. The nomination passes highly-selective panels at the school and the college level, and becomes a finalist for the university level.\n","date":1699619737,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699619737,"objectID":"f12ac0ad75339e9756ffec6a710a0e38","permalink":"https://luomai.github.io/post/23-rising-star/","publishdate":"2023-11-10T13:35:37+01:00","relpermalink":"/post/23-rising-star/","section":"post","summary":"I am nominated by the school for a Chancellor\u0026rsquo;s Rising Star in Research Award, a prestigious honour for young faculty joined University of Edinburgh between 2018 and 2023. The nomination passes highly-selective panels at the school and the college level, and becomes a finalist for the university level.","tags":[],"title":"[10/23, Award] Finalist for the Chancellor's Rising Star in Research.","type":"post"},{"authors":[],"categories":[],"content":"Gear system to appear in ICML 2023.\n","date":1694349337,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694349337,"objectID":"b2a5756f9e6a9003f7fead78685dcb68","permalink":"https://luomai.github.io/post/23-gear-icml/","publishdate":"2023-09-10T13:35:37+01:00","relpermalink":"/post/23-gear-icml/","section":"post","summary":"Gear system to appear in ICML 2023.","tags":[],"title":"[09/23, Paper] GEAR, a new training system for bridging RL and LLMs, accepted to ICML 2023.","type":"post"},{"authors":["Hanjing Wang*","Man-Kit Sit","Congjie He","Ying Wen","Weinan Zhang","Jun Wang","Yaodong Yang","Luo Mai"],"categories":null,"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682899200,"objectID":"2447d0864874b5dd6ea4cca31eee3a50","permalink":"https://luomai.github.io/publication/2023-icml-gear/","publishdate":"2023-05-01T00:00:00Z","relpermalink":"/publication/2023-icml-gear/","section":"publication","summary":" This paper introduces a distributed, GPU-centric experience replay system, GEAR, designed to perform scalable reinforcement learning (RL) with large sequence models (such as transformers). With such models, existing systems such as Reverb face considerable bottlenecks in mem- ory, computation, and communication. GEAR, however, optimizes memory efficiency by enabling the memory resources on GPU servers (including host memory and device memory) to manage trajectory data. Furthermore, it facilitates decentralized GPU devices to expedite vari- ous trajectory selection strategies, circumventing computational bottlenecks. GEAR is equipped with GPU kernels capable of collecting trajec- tories using zero-copy access to host memory, along with remote-directed-memory access over InfiniBand, improving communication efficiency. Cluster experiments have shown that GEAR can achieve performance levels up to 6× greater than Reverb when training state-of-the-art large RL models. GEAR is open-sourced at https:// github.com/bigrl-team/gear.","tags":["Machine Learning Systems"],"title":"GEAR: A GPU-Centric Experience Replay System for Large Reinforcement Learning Models","type":"publication"},{"authors":[],"categories":[],"content":"Our Paper \u0026ldquo;Ekko: A Large-Scale Deep Learning Recommender System with Low-Latency Model Update\u0026rdquo; is accepted by USENIX Symposium on Operating Systems Design and Implementation (OSDI) 2022. OSDI brings together professionals from academic and industrial backgrounds in what has become a premier forum for discussing the design, implementation, and implications of systems software. The symposium emphasizes innovative research as well as quantified or insightful experiences in systems design and implementation.\n","date":1671366937,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671366937,"objectID":"4fb1f746a8ea70cad215d31e0922d323","permalink":"https://luomai.github.io/post/22-ekko-osdi/","publishdate":"2022-12-18T13:35:37+01:00","relpermalink":"/post/22-ekko-osdi/","section":"post","summary":"Our Paper \u0026ldquo;Ekko: A Large-Scale Deep Learning Recommender System with Low-Latency Model Update\u0026rdquo; is accepted by USENIX Symposium on Operating Systems Design and Implementation (OSDI) 2022. OSDI brings together professionals from academic and industrial backgrounds in what has become a premier forum for discussing the design, implementation, and implications of systems software.","tags":[],"title":"[07/22, Paper] Ekko, the first system unifying training and inference, accepted to OSDI 2022","type":"post"},{"authors":["Chijun Sima","Yao Fu","Man-Kit Sit","Liyi Guo","Xuri Gong","Feng Lin","Junyu Wu","Yongsheng Li","Haidong Rong","Pierre-Louis Aublin","Luo Mai"],"categories":null,"content":"","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667260800,"objectID":"9f72ce46778e193faf5f89ec0d7d5c20","permalink":"https://luomai.github.io/publication/2022-osdi-ekko/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/publication/2022-osdi-ekko/","section":"publication","summary":"Deep Learning Recommender Systems (DLRSs) need to update models at low latency, thus promptly serving new users and content. Existing DLRSs, however, fail to do so. They train/validate models offline and broadcast entire models to global inference clusters. They thus incur significant model update latency (e.g. dozens of minutes), which adversely affects Service-Level Objectives (SLOs).\nThis paper describes Ekko, a novel DLRS that enables low-latency model updates. Its design idea is to allow model updates to be immediately disseminated to all inference clusters, thus bypassing long-latency model checkpoint, validation and broadcast. To realise this idea, we first design an efficient peer-to-peer model update dissemination algorithm. This algorithm exploits the sparsity and temporal locality in updating DLRS models to improve the throughput and latency of updating models. Further, Ekko has a model update scheduler that can prioritise, over busy networks, the sending of model updates that can largely affect SLOs. Finally, Ekko has an inference model state manager which monitors the SLOs of inference models and rollbacks the models if SLO-detrimental biased updates are detected. Evaluation results show that Ekko is orders of magnitude faster than state-of-the-art DLRS systems. Ekko has been deployed in production for more than one year, serves over a billion users daily and reduces the model update latency compared to state-of-the-art systems from dozens of minutes to 2.4 seconds.","tags":["Machine Learning Systems"],"title":"Ekko: A Large-Scale Deep Learning Recommender System with Low-Latency Model Update","type":"publication"},{"authors":null,"categories":null,"content":"MegBA is a fast and distributed library for large-scale Bundle Adjustment (BA). MegBA has a novel end-to-end vectorised BA algorithm which can fully exploit the massive parallel cores on GPUs, thus speeding up the entire BA computation. It also has a novel distributed BA algorithm that can automatically partition BA problems, and solve BA sub-problems using distributed GPUs. The GPUs synchronise intermediate solving state using network-efficient collective communication, and the synchronisation is designed to minimise communication cost. MegBA has a memory-efficient GPU runtime and it exposes g2o-compatible APIs. Experiments show that MegBA can out-perform state-of-the-art BA libraries (i.e., Ceres and DeepLM) by ~50x and ~5x respectively, in public large-scale BA benchmarks.\n","date":1667174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667174400,"objectID":"5bf4b9028fbc57df3e84b7f3c9803b8c","permalink":"https://luomai.github.io/project/megba/","publishdate":"2022-10-31T00:00:00Z","relpermalink":"/project/megba/","section":"project","summary":"A GPU-Based Distributed Library for Large-Scale Bundle Adjustment. [![GitHub stars](https://img.shields.io/github/stars/MegviiRobot/MegBA.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/MegviiRobot/MegBA/stargazers/)","tags":null,"title":"MegBA","type":"project"},{"authors":null,"categories":null,"content":"TorchOpt is an efficient library for differentiable optimization built upon PyTorch. TorchOpt is:\nComprehensive: TorchOpt provides three differentiation modes - explicit differentiation, implicit differentiation, and zero-order differentiation for handling different differentiable optimization situations.\nFlexible: TorchOpt provides both functional and objective-oriented API for users\u0026rsquo; different preferences. Users can implement differentiable optimization in JAX-like or PyTorch-like style.\nEfficient: TorchOpt provides (1) CPU/GPU acceleration differentiable optimizer (2) RPC-based distributed training framework (3) Fast Tree Operations, to largely increase the training efficiency for bi-level optimization problems.\nBeyond differentiable optimization, TorchOpt can also be regarded as a functional optimizer that enables JAX-like composable functional optimizer for PyTorch. With TorchOpt, users can easily conduct neural network optimization in PyTorch with a functional style optimizer, similar to Optax in JAX.\n","date":1667174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667174400,"objectID":"e1cd7fc096977242b4115cf1d519ec9f","permalink":"https://luomai.github.io/project/torchopt/","publishdate":"2022-10-31T00:00:00Z","relpermalink":"/project/torchopt/","section":"project","summary":"An efficient library for differentiable optimization built upon PyTorch. [![GitHub stars](https://img.shields.io/github/stars/metaopt/torchopt.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/metaopt/torchopt/stargazers/)","tags":null,"title":"TorchOpt","type":"project"},{"authors":["Bo Liu","Xidong Feng","Jie Ren","Luo Mai","Rui Zhu","Haifeng Zhang","Jun Wang","Yaodong Yang"],"categories":null,"content":"","date":1660521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660521600,"objectID":"0922d3edb8db4ccd6e5c2dc493c6f963","permalink":"https://luomai.github.io/publication/2022-neurips-settling/","publishdate":"2022-08-15T00:00:00Z","relpermalink":"/publication/2022-neurips-settling/","section":"publication","summary":"Gradient-based Meta-RL (GMRL) refers to methods that maintain two-level optimisation procedures wherein the outer-loop meta-learner guides the inner-loop gradient-based reinforcement learner to achieve fast adaptations. In this paper, we develop a unified framework that describes variations of GMRL algorithms and points out that existing stochastic meta-gradient estimators adopted by GMRL are actually \textbf{biased}. Such meta-gradient bias comes from two sources: 1) the compositional bias incurred by the two-level problem structure, which has an upper bound of (KαKσ̂ In|τ|−0.5) \u001bmph{w.r.t.} inner-loop update step K, learning rate α, estimate variance σ̂ 2In and sample size |τ|, and 2) the multi-step Hessian estimation bias Δ̂ H due to the use of autodiff, which has a polynomial impact ((K−1)(Δ̂ H)K−1) on the meta-gradient bias. We study tabular MDPs empirically and offer quantitative evidence that testifies our theoretical findings on existing stochastic meta-gradient estimators. Furthermore, we conduct experiments on Iterated Prisoner's Dilemma and Atari games to show how other methods such as off-policy learning and low-bias estimator can help fix the gradient bias for GMRL algorithms in general.","tags":["Machine Learning Systems"],"title":"A Theoretical Understanding of Gradient Bias in Meta-Reinforcement Learning","type":"publication"},{"authors":["Jie Ren","Wenteng Liang*","Ran Yan","Luo Mai","Shiwen Liu","Xiao Liu"],"categories":null,"content":"","date":1660089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660089600,"objectID":"20da1d22f97dcbf9095e52e3c0078653","permalink":"https://luomai.github.io/publication/2022-eccv-megba/","publishdate":"2022-08-10T00:00:00Z","relpermalink":"/publication/2022-eccv-megba/","section":"publication","summary":"Large-scale Bundle Adjustment (BA) requires massive memory and computation resources which are difficult to be fulfilled by existing BA libraries. In this paper, we propose MegBA, a GPU-based distributed BA library. MegBA can provide massive aggregated memory by automatically partitioning large BA problems, and assigning the solvers of sub-problems to parallel nodes. The parallel solvers adopt distributed Precondition Conjugate Gradient and distributed Schur Elimination, so that an effective solution, which can match the precision of those computed by a single node, can be efficiently computed. To accelerate BA computation, we implement end-to-end BA computation using high-performance primitives available on commodity GPUs. MegBA exposes easy-to-use APIs that are compatible with existing popular BA libraries. Experiments show that MegBA can significantly outperform state-of-the-art BA libraries: Ceres (41.45×), RootBA (64.576×) and DeepLM (6.769×) in several large-scale BA benchmarks. The code of MegBA is available at: https://github.com/MegviiRobot/MegBA.","tags":["Machine Learning Systems"],"title":"MegBA: A GPU-Based Distributed Library for Large-Scale Bundle Adjustment","type":"publication"},{"authors":[],"categories":[],"content":"Our Paper \u0026ldquo;MegBA: A GPU-Based Distributed Library for Large-Scale Bundle Adjustment\u0026rdquo; is accepted by ECCV 2022.\n","date":1657456537,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657456537,"objectID":"ad8e8e6c026bdfc6ea429e84f68831e7","permalink":"https://luomai.github.io/post/22-megba-eccv/","publishdate":"2022-07-10T13:35:37+01:00","relpermalink":"/post/22-megba-eccv/","section":"post","summary":"Our Paper \u0026ldquo;MegBA: A GPU-Based Distributed Library for Large-Scale Bundle Adjustment\u0026rdquo; is accepted by ECCV 2022.","tags":[],"title":"MegBA library in ECCV 2022","type":"post"},{"authors":["Le Xu","Shivaram Venkataraman","Indranil Gupta","Luo Mai","Rahul Potharaju"],"categories":null,"content":"","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"2b078c2eb38852aa4a7e6a7d45f62723","permalink":"https://luomai.github.io/publication/2021-nsdi-cameo/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/publication/2021-nsdi-cameo/","section":"publication","summary":"Resource provisioning in multi-tenant stream processing systems faces the dual challenges of keeping resource utilization high (without over-provisioning), and ensuring performance isolation. In our common production use cases, where stream-ing workloads have to meet latency targets and avoid breach-ing service-level agreements, existing solutions are in capable of handling the wide variability of user needs. Our framework called Cameo uses fine-grained stream processing (inspired by actor computation models), and is able to provide high resource utilization while meeting latency targets. Cameo dynamically calculates and propagates priorities of events based on user latency targets and query semantics.  Experiments on Microsoft Azure show that compared to state-of-the-art,the Cameo framework: i) reduces query latency by 2.7× in single tenant settings, ii) reduces query latency by 4.6× in multi-tenant scenarios, and iii) weathers transient spikes of workload.","tags":["Big Data Systems"],"title":"Move Fast and Meet Deadlines: Fine-grained Real-time Stream Processing with Cameo","type":"publication"},{"authors":null,"categories":null,"content":"The primary motivation for the Quiver project is to make it easy to take a PyG script and scale it across many GPUs and CPUs. A typical scenario is: Quiver users can leverage the high-level APIs and rich examples of PyG to design graph learning algorithms, and then use Quiver to scale PyG algorithms to run at large scale. To make such scaling efficient, Quiver has several features:\nHigh performance: Quiver enables GPUs to be efficiently used in accelerating performance-critical graph learning tasks: graph sampling, feature collection and data-parallel training. Quiver thus can out-perform PyG and DGL even with a single GPU, especially when processing large-scale datasets and models.\nHigh scalability: Quiver can achieve (super) linear scalability in distributed graph learning. This is contributed by Quiver\u0026rsquo;s novel communication-efficient data/processor management techniques and effective usage of fast networking technologies (e.g., NVLink and RDMA).\nEasy to use: Quiver requires only a few new lines of code in existing PyG programs and it has no external heavy dependency. Quiver is thus easy to be adopted by PyG users and integrated into production clusters.\n","date":1635638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635638400,"objectID":"0f69ae98615c8408e0a602a28ecbd81f","permalink":"https://luomai.github.io/project/quiver/","publishdate":"2021-10-31T00:00:00Z","relpermalink":"/project/quiver/","section":"project","summary":"PyTorch Library for Low-Latency, High-Throughput Graph Learning on GPUs. [![GitHub stars](https://img.shields.io/github/stars/quiver-team/torch-quiver.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/quiver-team/torch-quiver/stargazers/)","tags":null,"title":"Quiver","type":"project"},{"authors":["Zihan Ding","Tianyang Yu","Yanhua Huang","Hongming Zhang","Guo Li","Quancheng Guo","Luo Mai","Hao Dong"],"categories":null,"content":"","date":1628985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628985600,"objectID":"e1efa02d25fa9d46e59e2ed681f15cf4","permalink":"https://luomai.github.io/publication/2021-multimedia-rlzoo/","publishdate":"2020-08-15T00:00:00Z","relpermalink":"/publication/2021-multimedia-rlzoo/","section":"publication","summary":"Many multimedia developers are exploring for adopting Deep Re- inforcement Learning (DRL) techniques in their applications. They however often find such an adoption challenging. Existing DRL libraries provide poor support for prototyping DRL agents (i.e., models), customising the agents, and comparing the performance of DRL agents. As a result, the developers often report low efficiency in developing DRL agents. In this paper, we introduce RLzoo, a new DRL library that aims to make the development of DRL agents efficient. RLzoo provides developers with (i) high-level yet flexible APIs for prototyping DRL agents, and further customising the agents for best performance, (ii) a model zoo where users can import a wide range of DRL agents and easily compare their performance, and (iii) an algorithm that can automatically construct DRL agents with custom components (which are critical to improve agent’s perfor- mance in custom applications). Evaluation results show that RLzoo can effectively reduce the development cost of DRL agents, while achieving comparable performance with existing DRL libraries.","tags":["Machine Learning Systems"],"title":"Efficient Reinforcement Learning Development with RLzoo","type":"publication"},{"authors":["Yixiao Guo","Jiawei Liu","Guo Li","Luo Mai","Hao Dong"],"categories":null,"content":"","date":1628985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628985600,"objectID":"93ea281c902a1b615b9dd5f4104e0318","permalink":"https://luomai.github.io/publication/2021-multimedia-hyperpose/","publishdate":"2020-08-15T00:00:00Z","relpermalink":"/publication/2021-multimedia-hyperpose/","section":"publication","summary":"Estimating human pose is an important yet challenging task in multimedia applications. Existing pose estimation libraries target reproducing standard pose estimation algorithms. When it comes to customising these algorithms for real-world applications, none of the existing libraries can offer both the flexibility of developing custom pose estimation algorithms and the high-performance of executing these algorithms on commodity devices. In this paper, we introduce HyperPose, a novel flexible and high-performance pose estimation library. HyperPose provides expressive Python APIs that enable developers to easily customise pose estimation algorithms for their applications. It further provides a model inference engine highly optimised for real-time pose estimation. This engine can dynamically dispatch carefully designed pose estimation tasks to CPUs and GPUs, thus automatically achieving high utilisation of hardware resources irrespective of deployment environments. Extensive evaluation results show that HyperPose can achieve up to 3.1x∼7.3x higher pose estimation throughput compared to state-of-the-art pose estimation libraries without compromising es- timation accuracy. By 2021, HyperPose has received over 1000 stars on GitHub and attracted users from both industry and academy.","tags":["Machine Learning Systems"],"title":"Fast and Flexible Human Pose Estimation with HyperPose","type":"publication"},{"authors":[],"categories":[],"content":"Our Paper \u0026ldquo;Move Fast and Meet Deadlines: Fine-grained Real-time Stream Processing with Cameo\u0026rdquo; is accepted by USENIX Symposium on Networked Systems Design and Implementation (NSDI) 2021.\nNSDI focuses on the design principles, implementation, and practical evaluation of networked and distributed systems. Its goal is to bring together researchers from across the networking and systems community to foster a broad approach to addressing overlapping research challenges.\nNSDI provides a high-quality forum for presenting results and discussing ideas that further the knowledge and understanding of the networked systems community as a whole, continue a significant research dialog, or push the architectural boundaries of network services.\n","date":1625489155,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625489155,"objectID":"f7b94a217973bf189234c6c48dc3baf8","permalink":"https://luomai.github.io/post/21-cameo-accept-news/","publishdate":"2021-07-05T13:45:55+01:00","relpermalink":"/post/21-cameo-accept-news/","section":"post","summary":"Our Paper \u0026ldquo;Move Fast and Meet Deadlines: Fine-grained Real-time Stream Processing with Cameo\u0026rdquo; is accepted by USENIX Symposium on Networked Systems Design and Implementation (NSDI) 2021.\nNSDI focuses on the design principles, implementation, and practical evaluation of networked and distributed systems.","tags":[],"title":"Cameo system in NSDI 2021","type":"post"},{"authors":["Luo Mai","Guo Li","Marcel Wagenlander","Konstantinos Fertakis","Andrei-Octavian Brabete","Peter Pietzuch"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"deb03b1b9dd9328c25abc6d179f08693","permalink":"https://luomai.github.io/publication/2020-osdi-kungfu/","publishdate":"2020-12-14T00:00:00Z","relpermalink":"/publication/2020-osdi-kungfu/","section":"publication","summary":" When using distributed machine learning (ML) systems to train models on a cluster of worker machines, users must configure a large number of parameters: hyper-parameters (e.g. the batch size and the learning rate) affect model convergence; system parameters (e.g. the number of workers and their communication topology) impact training performance. In current systems, adapting such parameters during training is ill-supported. Users must set system parameters at deployment time, and provide fixed adaptation schedules for hyper-parameters in the training program. We describe KungFu, a distributed ML library for Tensor- Flow that is designed to enable adaptive training. KungFu allows user to express high-level Adaptation Policies (APs) that describe how to change hyper- and system parameters during training. APs take real-time monitored metrics (e.g. signal-to-noise ratios and noise scale) as input and trigger control actions (e.g. cluster rescaling or updating the synchronisation strategy). For execution, APs are translated into monitoring and control operators, which are embedded in the dataflow graph. APs exploit an efficient asynchronous collective communication layer, which ensures concurrency and consistency of monitoring and adaptation operations.","tags":["Machine Learning Systems"],"title":"KungFu: Making Training in Distributed Machine Learning Adaptive","type":"publication"},{"authors":[],"categories":[],"content":"Our Paper \u0026ldquo;KungFu: Making Training in Distributed Machine Learning Adaptive\u0026rdquo; is accepted by USENIX Symposium on Operating Systems Design and Implementation (OSDI) 2020.\nOSDI brings together professionals from academic and industrial backgrounds in what has become a premier forum for discussing the design, implementation, and implications of systems software. The symposium emphasizes innovative research as well as quantified or insightful experiences in systems design and implementation.\n","date":1597754137,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597754137,"objectID":"a29ffed6f8869959b067910c510c35e7","permalink":"https://luomai.github.io/post/20-kungfu-accept-news/","publishdate":"2020-08-18T13:35:37+01:00","relpermalink":"/post/20-kungfu-accept-news/","section":"post","summary":"Our Paper \u0026ldquo;KungFu: Making Training in Distributed Machine Learning Adaptive\u0026rdquo; is accepted by USENIX Symposium on Operating Systems Design and Implementation (OSDI) 2020.\nOSDI brings together professionals from academic and industrial backgrounds in what has become a premier forum for discussing the design, implementation, and implications of systems software.","tags":[],"title":"KungFu system in OSDI 2020","type":"post"},{"authors":null,"categories":null,"content":"Today\u0026rsquo;s machine learning systems must cope with growing complex models and increasingly complicated deployment environments, making them difficult to constantly deliver high performance with an empirical configuration. To address this, KungFu enables machine learning users to realise adaptive distributed training policies using high-level training monitoring and control APIs. KungFu has a fast and scalable runtime which can automatically scale out policy execution onto distributed GPU servers. Large-scale cluster experiments show that KungFu not only enables real-world adaptive training use cases, but also out-performs state-of-the-art distributed training systems including Horovod and Parameters Servers.\n","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"511bc777d1f6350b91dcaec24c2cc6fb","permalink":"https://luomai.github.io/project/kungfu/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/project/kungfu/","section":"project","summary":"Adaptive Large-scale Deep Learning [![GitHub stars](https://img.shields.io/github/stars/lsds/kungfu.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/lsds/kungfu/stargazers/)","tags":null,"title":"KungFu","type":"project"},{"authors":["Marcel Wagenlander","Luo Mai","Guo Li","Peter Pietzuch"],"categories":null,"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"f8af5e7249f7c40944769bd5268555f1","permalink":"https://luomai.github.io/publication/2020-hotcloud-spotnik/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/publication/2020-hotcloud-spotnik/","section":"publication","summary":"To achieve higher utilisation, cloud providers offer VMs with GPUs as lower-cost transient cloud resources. Transient VMs can be revoked at short notice and vary in their availability. This poses challenges to distributed machine learning (ML) jobs, which perform long-running stateful computation in which many workers maintain and synchronise model replicas. With transient VMs, existing systems either require a fixed number of reserved VMs or degrade performance when recovering from revoked transient VMs. We believe that future distributed ML systems must be de- signed from the ground up for transient cloud resources. This paper describes SPOTNIK, a system for training ML models that features a more adaptive design to accommodate transient VMs: (i) SPOTNIK uses an adaptive implementation of the all-reduce collective communication operation. As workers on transient VMs are revoked, SPOTNIK updates its membership and uses the all-reduce ring to recover; and (ii) SPOTNIK supports the adaptation of the synchronisation strategy between workers. This allows a training job to switch between different strategies in response to the revocation of transient VMs. Our experiments show that, after VM revocation, SPOTNIK recovers training within 300 ms for ResNet/ImageNet.","tags":["Machine Learning Systems","Cloud Computing"],"title":"Spotnik: Designing Distributed Machine Learning for Transient Cloud Resources","type":"publication"},{"authors":null,"categories":null,"content":"TensorLayer is a popular open-source TensorFlow-based deep learning and reinforcement library. It provides rich neural layers, pre-trained neural networks, data processing, model management and distributed training to facilitate the development of a wide spectrum of deep learning algorithms. TensorLayer has a transparent and flexible programming model, and thus suitable to customise deep neural networks for deployment and research purposes. It exhibits superior performance due to the low-cost integration with the TensorFlow backend. TensorLayer is easy to learn by providing massive tutorials, examples and real-world application codes. Since open-sourced in 2017, it has attracted more than 300,000 downloads, 6000 stars on Github, and 90 contributors around the world. TensorLayer is recently awarded the 2017 best open-source software by the prestigious ACM multimedia community.\n","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"802d61c9c8364c0f2a2655749425d54c","permalink":"https://luomai.github.io/project/tensorlayer/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/project/tensorlayer/","section":"project","summary":"Easy-to-use Deep Learning Library [![GitHub stars](https://img.shields.io/github/stars/tensorlayer/tensorlayer.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/tensorlayer/tensorlayer/stargazers/)","tags":null,"title":"TensorLayer","type":"project"},{"authors":null,"categories":null,"content":"Estimating human pose is a core task in many multimedia applications. To fully achieve its promise, users often need to customise pose estimation systems for best possible accuracy, and optimise the systems so that they can achieve real-time processing of high-resolution video streams. To meet these needs, we introduce HyperPose, a library for building pose estimation systems. HyperPose provides a large collection of high-level APIs to help users develop pose estimation algorithms that can achieve high accuracy in the wild. HyperPose further provides a high-performance algorithm execution engine. This engine has a high-performance dataflow for executing pose estimation algorithms. It dynamically dispatches dataflow operators onto CPUs/GPUs, which maximises hardware efficiency, thus achieving real-time processing. Evaluation result show that HyperPose allows users to declare many useful pose estimation algorithms. It also out-performs the performance of state-of-the-art pose estimation systems by up to 3.1x.\n","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"ed8e52ffeba07d28058b5554cd9c0009","permalink":"https://luomai.github.io/project/hyperpose/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/project/hyperpose/","section":"project","summary":"Real-time Visual Computing Library [![GitHub stars](https://img.shields.io/github/stars/tensorlayer/hyperpose.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/tensorlayer/hyperpose/stargazers/)","tags":null,"title":"HyperPose","type":"project"},{"authors":[],"categories":[],"content":"I am invited to give a talk: \u0026ldquo;Adaptive Distributed Training of Deep Learning Models\u0026rdquo; in the Workshop on AI Systems at ACM Symposium on Operating Systems Principles (SOSP) 2019.\n","date":1572958417,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572958417,"objectID":"5968be8748bb244455614375d150f9a4","permalink":"https://luomai.github.io/post/19-talk-sosp/","publishdate":"2019-11-05T13:53:37+01:00","relpermalink":"/post/19-talk-sosp/","section":"post","summary":"I am invited to give a talk: \u0026ldquo;Adaptive Distributed Training of Deep Learning Models\u0026rdquo; in the Workshop on AI Systems at ACM Symposium on Operating Systems Principles (SOSP) 2019.","tags":[],"title":"Invited talk in the AI systems workshop at SOSP 2019","type":"post"},{"authors":[],"categories":null,"content":"","date":1572181200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572181200,"objectID":"4e053c4645d288307aee6c84c1ac258f","permalink":"https://luomai.github.io/talk/2019-kungfu-sosp/","publishdate":"2019-10-27T13:00:00Z","relpermalink":"/talk/2019-kungfu-sosp/","section":"talk","summary":"Adaptive distributed training of deep learning models","tags":[],"title":"SOSP AI Systems Workshop","type":"talk"},{"authors":["Alexandros Koliousis","Pijika Watcharapichat","Matthias Weidlich","Luo Mai","Paolo Costa","Peter Pietzuch"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"0ebdd56ec8701114a5aba1877375c187","permalink":"https://luomai.github.io/publication/2019-vldb-crossbow/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/2019-vldb-crossbow/","section":"publication","summary":"Deep learning models are trained on servers with many GPUs, and training must scale with the number of GPUs. Systems such as TensorFlow and Caffe2 train models with parallel synchronous stochastic gradient descent: they process a batch of training data at a time, partitioned across GPUs, and average the resulting partial gradients to obtain an updated global model. To fully utilise all GPUs, systems must increase the batch size, which hinders statistical efficiency. Users tune hyper-parameters such as the learning rate to compensate for this, which is complex and model-specific. We describe Crossbow, a new single-server multi-GPU system for training deep learning models that enables users to freely choose their preferred batch size---however small---while scaling to multiple GPUs. Crossbow uses many parallel model replicas and avoids reduced statistical efficiency through a new synchronous training method. We introduce SMA, a synchronous variant of model averaging in which replicas independently explore the solution space with gradient descent, but adjust their search synchronously based on the trajectory of a globally-consistent average model. Crossbow achieves high hardware efficiency with small batch sizes by potentially training multiple model replicas per GPU, automatically tuning the number of replicas to maximise throughput. our experiments show that Crossbow improves the training time of deep learning models on an 8-GPU server by 1.3--4X compared to TensorFlow.","tags":["Machine Learning Systems"],"title":"CrossBow: Scaling Deep Learning with Small Batch Sizes on Multi-GPU Servers","type":"publication"},{"authors":null,"categories":null,"content":"Deep Reinforcement Learning (DRL) has become the foundation of many multimedia applications. To fully achieve its promise, multi-media users are looking for a library that allows them to efficiently design and test DRL agents and integrate the agents into their ap-plications. In this project, we introduce RLzoo, a novel DRL library that makes it easy to design, test and deploy DRL agents. RLzoo has high-level expressive APIs which enable its users to efficiently develop DRL agents. RLzoo users can leverage an automatic agent construction algorithm to seamlessly adopt custom agent modules,e.g., custom neural networks, which is the key for tuning agents for achieving the best possible performance. RLzoo users can access a large number of pre-implemented DRL environments and algorithms, making it a comprehensive DRL platform. On this platform,users can further easily manage and tune DRL agents through an interactive training terminal. Evaluation results show that: com-pared to existing DRL libraries, RLzoo not only achieves a high degree of abstraction in its API design. It also provides numerous useful DRL algorithms and environments which are not available in other libraries.\n","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"c5967a74fd45d0f76d15d8220147f41b","permalink":"https://luomai.github.io/project/rlzoo/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/project/rlzoo/","section":"project","summary":"Reinforcement Learning Model Zoo [![GitHub stars](https://img.shields.io/github/stars/tensorlayer/rlzoo.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/tensorlayer/rlzoo/stargazers/)","tags":null,"title":"RLzoo","type":"project"},{"authors":["Luo Mai","Alexandros Koliousis","Guo Li","Andrei-Octavian Brabete","Peter Pietzuch"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"2b881ac3ec380aa87e2437d60162c356","permalink":"https://luomai.github.io/publication/2019-osr-review/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/2019-osr-review/","section":"publication","summary":"Deep learning (DL) systems expose many tuning parameters (“hyper-parameters”) that affect the performance and accuracy of trained models. Increasingly users struggle to configure hyper-parameters, and a substantial portion of time is spent tuning them empirically. We argue that future DL systems should be designed to help manage hyper-parameters. We describe how a distributed DL system can (i) remove the impact of hyper-parameters on both performance and accuracy, thus making it easier to decide on a good setting, and (ii) support more powerful dynamic policies for adapting hyper-parameters, which take monitored training metrics into account. We report results from prototype implementations that show the practicality of DL system designs that are hyper-parameter-friendly.","tags":["Machine Learning Systems"],"title":"Taming Hyper-parameters in Deep Learning Systems","type":"publication"},{"authors":[],"categories":null,"content":"","date":1543669200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543669200,"objectID":"5bdd4cabffc0f500301ba9c8fec2973a","permalink":"https://luomai.github.io/talk/2018-google-devfest/","publishdate":"2018-12-01T13:00:00Z","relpermalink":"/talk/2018-google-devfest/","section":"talk","summary":"TensorLayer: A flexible library for deep learning researchers and developers","tags":[],"title":"Google Developer Festival","type":"talk"},{"authors":["Luo Mai","Kai Zeng","Rahul Potharaju","Le Xu","Shivaram Venkataraman","Paolo Costa","Terry Kim","Saravanan Muthukrishnan","Vamsi Kuppa","Sudheer Dhulipalla","Sriram Rao"],"categories":null,"content":"","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"78143f48499166d71e098a960676c04d","permalink":"https://luomai.github.io/publication/2018-vldb-chi/","publishdate":"2018-07-01T00:00:00Z","relpermalink":"/publication/2018-vldb-chi/","section":"publication","summary":"Stream-processing workloads and modern shared cluster environments exhibit high variability and unpredictability. Combined with the large parameter space and the diverse set of user SLOs, this makes modern streaming systems very challenging to statically configure and tune. To address these issues, in this paper we investigate a novel control-plane design, Chi, which supports continuous monitoring and feedback, and enables dynamic re-configuration. Chi leverages the key insight of embedding control-plane messages in the data-plane channels to achieve a low-latency and flexible control plane for stream-processing systems. Chi introduces a new reactive programming model and design mechanisms to asynchronously execute control policies, thus avoiding global synchronization. We show how this allows us to easily implement a wide spectrum of control policies targeting different use cases observed in production. Large-scale experiments using production workloads from a popular cloud provider demonstrate the flexibility and efficiency of our approach.","tags":["Big Data Systems"],"title":"Chi: A Scalable and Programmable Control Plane for Distributed Stream Processing Systems","type":"publication"},{"authors":["Nik Sultana","Salvator Galea","David Greaves","Marcin Wojcik","Jonny Shipton","Richard Clegg","Luo Mai","Pietro Bressana","Robert Soule","Richard Mortier","Paolo Costa","Peter Pietzuch","Jon Crowcroft","Andrew W Moore","Noa Zilberman"],"categories":null,"content":"","date":1501545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501545600,"objectID":"b5e6461c44a15dd286fce83f95e8aee2","permalink":"https://luomai.github.io/publication/2017-atc-emu/","publishdate":"2017-08-01T00:00:00Z","relpermalink":"/publication/2017-atc-emu/","section":"publication","summary":"Due to their performance and flexibility, FPGAs are an attractive platform for the execution of network functions. It has been a challenge for a long time though to make FPGA programming accessible to a large audience of developers. An appealing solution is to compile code from a general-purpose language to hardware using high-level synthesis. Unfortunately, current approaches to implement rich network functionality are insufficient because they lack: (i) libraries with abstractions for common network operations and data structures, (ii) bindings to the underlying “substrate” on the FPGA, and (iii) debugging and profiling support. This paper describes Emu, a new standard library for an FPGA hardware compiler that enables developers to rapidly create and deploy network functionality. Emu allows for high-performance designs without being bound to particular packet processing paradigms. Furthermore, it supports running the same programs on CPUs, in Mininet, and on FPGAs, providing a better development environment that includes advanced debugging capabilities. We demonstrate that network functions implemented using Emu have only negligible resource and performance overheads compared with natively-written hardware versions.","tags":["Data Centre Networks"],"title":"Emu: Rapid Prototyping of Networking Services","type":"publication"},{"authors":["Hao Dong","Akara Supratak","Luo Mai","Fangde Liu","Axel Oehmichen","Simiao Yu","Yike Guo"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"df83558d9fa95a003b3db9795ca5abf2","permalink":"https://luomai.github.io/publication/2017-multimedia-tensorlayer/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publication/2017-multimedia-tensorlayer/","section":"publication","summary":"Recently we have observed emerging uses of deep learning techniques in multimedia systems. Developing a practical deep learning system is arduous and complex. It involves labor-intensive tasks for constructing sophisticated neural networks, coordinating multiple network models, and managing a large amount of training-related data. To facilitate such a development process, we propose TensorLayer which is a Python-based versatile deep learning library. TensorLayer provides high-level modules that abstract sophisticated operations towards neuron layers, network models, training data and dependent training jobs. In spite of offering simplicity, it has transparent module interfaces that allows developers to flexibly embed low-level controls within a backend engine, with the aim of supporting fine-grain tuning towards training. Real-world cluster experiment results show that TensorLayeris able to achieve competitive performance and scalability in critical deep learning tasks. TensorLayer was released in September 2016 on GitHub. Since after, it soon become one of the most popular open-sourced deep learning library used by researchers and practitioners.","tags":["Machine Learning Systems"],"title":"TensorLayer: A Versatile Library for Efficient Deep Learning Development","type":"publication"},{"authors":["Abdul Alim","Richard G. Clegg","Luo Mai","Lukas Rupprecht","Eric Seckler","Paolo Costa","Peter Pietzuch","Alexander L. Wolf","Nik Sultana","Jon Crowcroft","Anil Madhavapeddy","Andrew Moore","Richard Mortier","Luis Oviedo","Masoud Koleni","Derek McAuley","Matteo Migliavacca"],"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"7cfc2cbb955075a97335eab5c7c29dd6","permalink":"https://luomai.github.io/publication/2016-atc-flick/","publishdate":"2016-08-01T00:00:00Z","relpermalink":"/publication/2016-atc-flick/","section":"publication","summary":"Data centre networks are increasingly programmable, with application-specific network services proliferating, from custom load-balancers to middleboxes providing caching and aggregation. Developers must currently implement these services using traditional low-level APIs, which neither support natural operations on application data nor provide efficient performance isolation. We describe FLICK, a framework for the programming and execution of application-specific network services on multi-core CPUs. Developers write network services in the FLICK language, which offers high-level processing constructs and application-relevant data types. FLICK programs are translated automatically to efficient, parallel task graphs, implemented in C++ on top of a user-space TCP stack. Task graphs have bounded resource usage at runtime, which means that the graphs of multiple services can execute concurrently without interference using cooperative scheduling. We evaluate FLICK with several services (an HTTP load-balancer, a Memcached router and a Hadoop data aggregator), showing that it achieves good performance while reducing development effort.","tags":["Data Centre Networks","Big Data Systems"],"title":"Flick: Developing and Running Application-specific Network Services ","type":"publication"},{"authors":["Da Yu","Luo Mai","Somaya Arianfar","Rodrigo Fonseca","Orran Krieger","David Oran"],"categories":null,"content":"","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467331200,"objectID":"8c76da1be60380cb77551e9aa9ddd7cd","permalink":"https://luomai.github.io/publication/2016-hotcloud-netex/","publishdate":"2016-07-01T00:00:00Z","relpermalink":"/publication/2016-hotcloud-netex/","section":"publication","summary":"Virtually all public clouds today are run by single providers, and this creates near-monopolies, inefficient markets, and hinders innovation at the infrastructure level. There are current proposals to change this, by creating open architectures that allow providers of computing and storage resources to compete for tenant services at multiple levels, all the way down to the bare metal. Networking, however, is not part of this, and is viewed as a commodity much like power or cooling. In this paper we borrow ideas from the Internet architecture, and propose to structure the cloud datacenter network as a marketplace where multiple service providers can offer connectivity services to tenants. Our marketplace, NetEx, divides the network into independently managed pods of resources, interconnected with multiple providers through special programmable switches that play a role analogous to that of an IXP. We demonstrate the feasibility of such an architecture by a prototype in Mininet, and argue that this can be a way to provide innovation, competition, and efficiency in future cloud datacenter networks.","tags":["Cloud Computing"],"title":"Towards a Network Marketplace in a Cloud","type":"publication"},{"authors":["Luo Mai","Chuntao Hong","Paolo Costa"],"categories":null,"content":"","date":1435708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435708800,"objectID":"b9af09566036effe01693fbd7417c92a","permalink":"https://luomai.github.io/publication/2015-hotcloud-mlnet/","publishdate":"2015-07-01T00:00:00Z","relpermalink":"/publication/2015-hotcloud-mlnet/","section":"publication","summary":"To cope with the ever growing availability of training data, there have been several proposals to scale machine learning computation beyond a single server and distribute it across a cluster. While this enables reducing the training time, the observed speed up is often limited by network bottlenecks. To address this, we design MLNET, a host-based communication layer that aims to improve the network performance of distributed machine learning systems. This is achieved through a combination of traffic reduction techniques (to diminish network load in the core and at the edges) and traffic management (to reduce average training time). A key feature of MLNET is its compatibility with existing hardware and software infrastructure so it can be immediately deployed. We describe the main techniques underpinning ML- NET and show through simulation that the overall training time can be reduced by up to 78%. While preliminary, our results indicate the critical role played by the network and the benefits of introducing a new communication layer to increase the performance of distributed machine learning systems.","tags":["Machine Learning Systems"],"title":"Optimizing Network Performance in Distributed Machine Learning","type":"publication"},{"authors":["Luo Mai","Lukas Rupprecht","Abdul Alim","Paolo Costa","Matteo Migliavacca","Peter Pietzuch","Alexander L. Wolf"],"categories":null,"content":"","date":1417392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417392000,"objectID":"b5afacccb120fcc5840643a1cfe54989","permalink":"https://luomai.github.io/publication/2014-conext-netagg/","publishdate":"2014-12-01T00:00:00Z","relpermalink":"/publication/2014-conext-netagg/","section":"publication","summary":"Data centre applications for batch processing (e.g. map/reduce frameworks) and online services (e.g. search engines) scale by distributing data and computation across many servers. They typically follow a partition/aggregation pattern: tasks are first partitioned across servers that process data locally, and then those partial results are aggregated. This data aggregation step, however, shifts the performance bottleneck to the network, which typically struggles to support many-to-few, high-bandwidth traffic between servers. Instead of performing data aggregation at edge servers, we show that it can be done more efficiently along network paths. We describe NETAGG, a software platform that supports on-path aggregation for network-bound partition/aggregation applications. NET-AGG exploits a middlebox-like design, in which dedicated servers (agg boxes) are connected by high-bandwidth links to network switches. Agg boxes execute aggregation functions provided by ap- plications, which alleviates network hotspots because only a fraction of the incoming traffic is forwarded at each hop. NETAGG requires only minimal application changes: it uses shim layers on edge servers to redirect application traffic transparently to the agg boxes. Our experimental results show that NETAGG improves substantially the throughput of two sample applications, the Solr distributed search engine and the Hadoop batch processing framework. Its design allows for incremental deployment in existing data centres and incurs only a modest investment cost.","tags":["Data Centre Networks","Big Data Systems"],"title":"NetAgg: Using Middleboxes for Application-specific On-path Aggregation in Data Centres","type":"publication"},{"authors":["Luo Mai","Evangelia Kalyvianaki","Paolo Costa"],"categories":null,"content":"","date":1385856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385856000,"objectID":"9221ab2bfeabe9c6199812e0827c0b25","permalink":"https://luomai.github.io/publication/2013-ladis-mai/","publishdate":"2013-12-01T00:00:00Z","relpermalink":"/publication/2013-ladis-mai/","section":"publication","summary":"Existing cloud provisioning schemes allocate re- sources to batch processing systems at deployment time and only change this allocation at run-time due to unexpected events such as server failures. We observe that MapReduce-like jobs are time- malleable, i.e., at runtime it is possible to dynamically vary the number of resources allocated to a job and, hence, its completion time. In this paper, we propose a novel approach based on time-malleability to opportunistically update job resources in order to increase overall utilization and revenue. To set the right incentives for both providers and tenants, we introduce a novel pricing model that charges tenants according to job completion times. Using this model, we formulate an optimization problem for revenue maximization. Preliminary results show that compared to today’s practices our solution can increase revenue by up to 69.7% and can accept up to 57% more jobs.","tags":["Cloud Computing"],"title":"Exploiting Time-malleability in Cloud-based Batch Processing Systems","type":"publication"},{"authors":["Luo Mai","Longfei Shangguan","Chao Lang","Junzhao Du","Zhenjiang Li","Mo Li"],"categories":null,"content":"","date":1322697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1322697600,"objectID":"a13bae634b4f93dcf87a1cea80752334","permalink":"https://luomai.github.io/publication/2011-mass-mai/","publishdate":"2011-12-01T00:00:00Z","relpermalink":"/publication/2011-mass-mai/","section":"publication","summary":"We study the rendezvous data collection problem for the mobile sink in wireless sensor networks. We introduce to jointly optimize trajectory planning for the mobile sink and workload balancing for the network. By doing so, the mobile sink is able to efficiently collect network-wide data within a given delay bound and the network can eliminate the energy bottleneck to dramatically prolong its lifetime. Such a joint optimization problem is shown to be NP-hard and we propose an approximation algorithm, named RPS-LB, to approach the optimal solution. In RPS-LB, according to observed properties of the median reference structure in the network, a series of Rendezvous Points (RPs) are selected to construct the trajectory for the mobile sink and the derived approximation ratio of RPS- LB guarantees that the formed trajectory is comparable with the optimal solution. The workload allocated to each RP is proven to be balanced mathematically. We then relax the assumption that mobile sink knows the location of each sensor node and present a localized, fully distributed version, RPS-LB-D, which largely improves the system applicability in practice. We verify the effectiveness of our proposals via extensive experiments.","tags":["Mobile Computing"],"title":"Load Balanced Rendezvous Data Collection in Wireless Sensor Networks","type":"publication"}]